{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27371980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.models import InnerProductDecoder\n",
    "import numpy as np\n",
    "from torch.nn import Parameter as Param, Linear\n",
    "from torch import nn\n",
    "from torch_geometric.nn.conv import GATv2Conv, MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.manual_seed(29)\n",
    "np.random.seed(29)\n",
    "EPS = 1e-13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b14a75",
   "metadata": {},
   "source": [
    "## Custom defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2717745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auprc_auroc_ap(target_tensor, score_tensor):\n",
    "    y = target_tensor.detach().cpu().numpy()\n",
    "    pred = score_tensor.detach().cpu().numpy()\n",
    "    auroc, ap = metrics.roc_auc_score(y, pred), metrics.average_precision_score(y, pred)\n",
    "    y, xx, _ = metrics.precision_recall_curve(y, pred)\n",
    "    auprc = metrics.auc(xx, y)\n",
    "\n",
    "    return auprc, auroc, ap\n",
    "\n",
    "def get_range_list(edge_list):\n",
    "    tmp = []\n",
    "    s = 0\n",
    "    for i in edge_list:\n",
    "        tmp.append((s, s + i.shape[1]))\n",
    "        s += i.shape[1]\n",
    "    return torch.tensor(tmp)\n",
    "\n",
    "def negative_sampling(pos_edge_index, num_nodes, num_dis):\n",
    "\n",
    "    idx = (pos_edge_index[0] * num_nodes + pos_edge_index[1])\n",
    "    idx = idx.to(torch.device('cpu'))\n",
    "\n",
    "    perm = torch.tensor(np.random.choice(num_nodes*num_dis, idx.size(0)))\n",
    "    mask = torch.from_numpy(np.isin(perm, idx).astype(np.uint8))\n",
    "    rest = mask.nonzero().view(-1)\n",
    "\n",
    "    while rest.numel() > 0:\n",
    "        tmp = torch.tensor(np.random.choice(num_nodes*num_dis, rest.size(0)))\n",
    "        mask = torch.from_numpy(np.isin(tmp, idx).astype(np.uint8))\n",
    "        perm[rest] = tmp\n",
    "        rest = mask.nonzero().view(-1)\n",
    "    row, col = perm / num_nodes, perm % num_nodes\n",
    "    returnable = torch.stack([row, col], dim=0).long().to(pos_edge_index.device)\n",
    "    return returnable\n",
    "\n",
    "def typed_negative_sampling(pos_edge_index, num_nodes, num_dis, range_list):\n",
    "    \n",
    "    tmp = []\n",
    "    for start, end in range_list:\n",
    "        tmp.append(negative_sampling(pos_edge_index[:, start: end], num_nodes, num_dis))\n",
    "        \n",
    "    value = torch.cat(tmp, dim=1)\n",
    "    return value\n",
    "\n",
    "def process_edges(raw_edge_list, p=0.9):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    train_label_list = []\n",
    "    test_label_list = []\n",
    "\n",
    "    train_mask = np.random.binomial(1, p, raw_edge_list.shape[1])\n",
    "    test_mask = 1 - train_mask\n",
    "    train_set = train_mask.nonzero()[0]\n",
    "    test_set = test_mask.nonzero()[0]\n",
    "\n",
    "    train_list.append(raw_edge_list[:, train_set])\n",
    "    test_list.append(raw_edge_list[:, test_set])\n",
    "\n",
    "    train_label_list.append(torch.ones(2 * train_set.size, dtype=torch.long))\n",
    "    test_label_list.append(torch.ones(2 * test_set.size, dtype=torch.long))\n",
    "\n",
    "    train_range = get_range_list(train_list)\n",
    "    test_range = get_range_list(test_list)\n",
    "\n",
    "    train_edge_idx = torch.cat(train_list, dim=1)\n",
    "    test_edge_idx = torch.cat(test_list, dim=1)\n",
    "\n",
    "    train_et = torch.cat(train_label_list)\n",
    "    test_et = torch.cat(test_label_list)\n",
    "    \n",
    "    return train_edge_idx, train_et, train_range, test_edge_idx, test_et, test_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc6c45",
   "metadata": {},
   "source": [
    "## Custom Graph Convolution For Cross Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd29f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEdgeConv(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim,\n",
    "                 unique_source_num, unique_target_num,\n",
    "                 is_after_relu=True, is_bias=False, **kwargs):\n",
    "\n",
    "        super(CrossEdgeConv, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.unique_source_num = unique_source_num\n",
    "        self.unique_target_num = unique_target_num\n",
    "        self.is_after_relu = is_after_relu\n",
    "\n",
    "        self.weight = Param(torch.Tensor(in_dim, out_dim))\n",
    "\n",
    "        if is_bias:\n",
    "            self.bias = Param(torch.Tensor(out_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.is_after_relu:\n",
    "            self.weight.data.normal_(std=1/np.sqrt(self.in_dim))\n",
    "        else:\n",
    "            self.weight.data.normal_(std=2/np.sqrt(self.in_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, range_list):\n",
    "        return self.propagate(edge_index, x=x, range_list=range_list)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, range_list):\n",
    "        if self.bias:\n",
    "            aggr_out += self.bias\n",
    "\n",
    "        out = torch.matmul(aggr_out[self.unique_source_num:, :], self.weight)\n",
    "        assert out.shape[0] == self.unique_target_num\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}'.format(self.__class__.__name__, self.in_dim, self.out_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77e06c",
   "metadata": {},
   "source": [
    "## Integrated GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f60eb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Setting(object):\n",
    "    def __init__(self, sp_rate=0.9, lr=0.01, prot_drug_dim=16, prot_dis_dim = 16, n_drug_embed=64,\n",
    "                n_dis_embed=64, n_hid1=32, n_hid2=16) -> None:\n",
    "        super().__init__()\n",
    "        self.sp_rate = sp_rate\n",
    "        self.lr = lr\n",
    "        self.prot_drug_dim = prot_drug_dim\n",
    "        self.prot_dis_dim = prot_dis_dim\n",
    "        self.n_drug_embed = n_drug_embed\n",
    "        self.n_dis_embed = n_dis_embed\n",
    "        self.n_hid1 = n_hid1\n",
    "        self.n_hid2 = n_hid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d154a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DrugDiseaseGNN(torch.nn.Module):\n",
    "    def __init__(self, settings:Setting, device, mod='cat', data_path='../data/final_processed/final_data_dict.pkl', ) -> None:\n",
    "        super().__init__()\n",
    "        self.mod = mod\n",
    "        self.device = device\n",
    "        self.settings = settings\n",
    "        self.data = self.__prepare_data(data_path, settings.sp_rate).to(device)\n",
    "        self.__prepare_model()\n",
    "\n",
    "\n",
    "    def __prepare_data(self, data_path, sp_rate):\n",
    "\n",
    "        with open(data_path, 'rb') as f:\n",
    "            data_dict = pickle.load(f)\n",
    "        data = Data.from_dict(data_dict)\n",
    "        \n",
    "        data.dd_train_idx, data.dd_train_et, data.dd_train_range, data.dd_test_idx, data.dd_test_et, data.dd_test_range = process_edges(data.dd_edge_index, p=sp_rate)\n",
    "        self.test_neg_index = typed_negative_sampling(data.dd_test_idx, data.n_drug, data.n_dis, data.dd_test_range)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __get_ndata__(self):\n",
    "        return self.data.n_drug_feat, self.data.n_drug, self.data.p_feat.shape[1], self.data.n_prot, self.data.n_dis_feat, self.data.n_dis\n",
    "\n",
    "    def __get_dimset__(self):\n",
    "        return self.settings.prot_drug_dim, self.settings.prot_dis_dim, self.settings.n_drug_embed, self.settings.n_dis_embed,self.settings.n_hid1, self.settings.n_hid2\n",
    "\n",
    "    def __prepare_model(self):\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        self.encoder = EndToEndEncoder(\n",
    "            self.device,\n",
    "            *self.__get_ndata__(), \n",
    "            *self.__get_dimset__()\n",
    "        ).to(self.device)\n",
    "\n",
    "        # decoder\n",
    "        \n",
    "#         self.decoder = MultiInnerProductDecoder(\n",
    "#             self.settings.n_hid2\n",
    "#         ).to(self.device)\n",
    "        \n",
    "        self.decoder = NNDecoder(\n",
    "            self.settings.n_hid2, self.settings.n_hid2,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        self.prot_embeddings, self.embeddings1, self.embeddings2 = self.encoder(self.data.d_feat, self.data.dis_feat, self.data.p_feat,                                       self.data.pp_train_indices, self.data.dp_edge_index, \n",
    "                                       self.data.dp_range_list, self.data.disp_edge_index, self.data.disp_range_list)\n",
    "\n",
    "        pos_index = self.data.dd_train_idx\n",
    "        neg_index = typed_negative_sampling(self.data.dd_train_idx, self.data.n_drug, self.data.n_dis, self.data.dd_train_range).type_as(pos_index)\n",
    "\n",
    "# Use with InnerProduct Decoder\n",
    "#         pos_score = self.decoder(self.embeddings1, self.embeddings2, pos_index, self.data.dd_train_et)\n",
    "#         neg_score = self.decoder(self.embeddings1, self.embeddings2, neg_index, self.data.dd_train_et)\n",
    "\n",
    "        pos_score = self.decoder(self.embeddings1, self.embeddings2, pos_index)\n",
    "        neg_score = self.decoder(self.embeddings1, self.embeddings2, neg_index)\n",
    "\n",
    "        pos_loss = -torch.log(pos_score + EPS).mean()\n",
    "        neg_loss = -torch.log(1 - neg_score + EPS).mean()\n",
    "        loss = pos_loss + neg_loss\n",
    "\n",
    "        return loss, (self.prot_embeddings, self.embeddings1, self.embeddings2)\n",
    "\n",
    "    def test(self, print_output=True):\n",
    "        \n",
    "        self.eval()\n",
    "        \n",
    "# Use with InnerProduct Decoder\n",
    "#         pos_score = self.decoder(self.embeddings1, self.embeddings2, self.data.dd_test_idx, self.data.dd_test_et)\n",
    "#         neg_score = self.decoder(self.embeddings1, self.embeddings2, self.test_neg_index, self.data.dd_test_et)\n",
    "\n",
    "        pos_score = self.decoder(self.embeddings1, self.embeddings2, self.data.dd_test_idx)\n",
    "        neg_score = self.decoder(self.embeddings1, self.embeddings2, self.test_neg_index)\n",
    "\n",
    "        return self.compute_auprc_auroc_ap_by_et(pos_score, neg_score, self.data.dd_test_range, print_output)\n",
    "\n",
    "    def compute_auprc_auroc_ap_by_et(self, pos_score, neg_score, dd_range, print_out):\n",
    "        \n",
    "        n_dd_et = dd_range.shape[0]\n",
    "        record = np.zeros((3, n_dd_et))     # auprc, auroc, ap\n",
    "        for i in range(dd_range.shape[0]):\n",
    "            [start, end] = dd_range[i]\n",
    "            p_s = pos_score[start: end]\n",
    "            n_s = neg_score[start: end]\n",
    "\n",
    "            pos_target = torch.ones(p_s.shape[0])\n",
    "            neg_target = torch.zeros(n_s.shape[0])\n",
    "\n",
    "            score = torch.cat([p_s, n_s])\n",
    "            target = torch.cat([pos_target, neg_target])\n",
    "\n",
    "            record[0, i], record[1, i], record[2, i] = auprc_auroc_ap(target, score)\n",
    "\n",
    "        if print_out:\n",
    "            [auprc, auroc, ap] = record.sum(axis=1) / n_dd_et\n",
    "\n",
    "            print('Test set Results:\\nAUPRC:{:0.4f}   AUCROC:{:0.4f}   AP@50:{:0.4f}'.format(auprc, auroc, ap))\n",
    "\n",
    "        return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e778f07",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40f6b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hid1=32, hid2=16):\n",
    "        super(PPEncoder, self).__init__()\n",
    "        self.out_dim = hid2\n",
    "\n",
    "        self.conv1 = GATv2Conv(in_dim, hid1)\n",
    "        self.conv2 = GATv2Conv(hid1, hid2)\n",
    "        self.Linear = Linear(hid2, hid2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.Linear(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class EndToEndEncoder(torch.nn.Module):   \n",
    "        \n",
    "    def __init__(\n",
    "                self, device, n_drug_feat, n_drug, n_prot_feat, n_prot, n_dis_feat, n_dis,\n",
    "                prot_drug_dim=16,\n",
    "                prot_dis_dim=16,\n",
    "                n_drug_embed=64,\n",
    "                n_dis_embed=64,\n",
    "                n_hid1=32, \n",
    "                n_hid2=16, \n",
    "                mod='cat'):\n",
    "\n",
    "        super(EndToEndEncoder, self).__init__()\n",
    "\n",
    "        self.out_dim = n_hid2\n",
    "        self.uni_num_drug = n_drug\n",
    "        self.uni_num_prot = n_prot\n",
    "        self.uni_num_dis = n_dis\n",
    "\n",
    "        # mod\n",
    "        self.mod = mod\n",
    "\n",
    "        # on pp-net\n",
    "        self.pp_encoder = PPEncoder(n_prot_feat)\n",
    "\n",
    "        # on pd-net\n",
    "        self.hgcn1 = CrossEdgeConv(self.pp_encoder.out_dim, prot_drug_dim, n_prot, n_drug)\n",
    "        self.hdrug = torch.zeros((self.uni_num_drug, self.pp_encoder.out_dim)).to(device)\n",
    "        \n",
    "        # on pdis-net\n",
    "        self.hgcn2 = CrossEdgeConv(self.pp_encoder.out_dim, prot_dis_dim, n_prot, n_dis)\n",
    "        self.hdis = torch.zeros((self.uni_num_dis, self.pp_encoder.out_dim)).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x_drug, x_dis, x_prot, \n",
    "                pp_edge_index, dp_edge_index, dp_range_list, disp_edge_index, disp_range_list):\n",
    "        \n",
    "        # pp-net\n",
    "        \n",
    "        x_prot = self.pp_encoder(x_prot, pp_edge_index)\n",
    "\n",
    "        # pd-net\n",
    "        x_drug = torch.cat((x_prot, self.hdrug))\n",
    "        x_drug = self.hgcn1(x_drug, dp_edge_index, dp_range_list)\n",
    "        \n",
    "        #pdis-net\n",
    "        x_dis = torch.cat((x_prot, self.hdis))\n",
    "        x_dis = self.hgcn2(x_dis, disp_edge_index, disp_range_list)\n",
    "        \n",
    "        return (x_prot, x_drug, x_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0898e7c",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb0f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInnerProductDecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim):\n",
    "        super(MultiInnerProductDecoder, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.weight = Param(torch.Tensor(1, in_dim))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, z2, z1, edge_index, sigmoid=True):\n",
    "\n",
    "        value = (z1[edge_index[0]] * z2[edge_index[1]] * self.weight[0]).sum(dim=1)\n",
    "        return torch.sigmoid(value)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.normal_(std=1/np.sqrt(self.in_dim))\n",
    "\n",
    "\n",
    "class NNDecoder(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, in_dim_drug, in_dim_dis, l1_dim=16):\n",
    "\n",
    "        super(NNDecoder, self).__init__()\n",
    "        self.l1_dim = l1_dim\n",
    "\n",
    "        # for drug \n",
    "        self.w1_l1 = Param(torch.Tensor(in_dim_drug, l1_dim))\n",
    "        self.w1_l2 = Param(torch.Tensor(1, l1_dim))  \n",
    "\n",
    "        # for disease\n",
    "        self.w2_l1 = Param(torch.Tensor(in_dim_dis, l1_dim))\n",
    "        self.w2_l2 = Param(torch.Tensor(1, l1_dim))  \n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, z2, z1, edge_index):\n",
    "        \n",
    "        # layer 1\n",
    "        d1 = torch.matmul(z1[edge_index[0]], self.w1_l1)\n",
    "        d2 = torch.matmul(z2[edge_index[1]], self.w2_l1)\n",
    "        d1 = F.relu(d1, inplace=True)\n",
    "        d2 = F.relu(d2, inplace=True)\n",
    "\n",
    "        # layer 2\n",
    "        d1 = (d1 * self.w1_l2[0]).sum(dim=1)\n",
    "        d2 = (d2 * self.w2_l2[0]).sum(dim=1)\n",
    "\n",
    "        return torch.sigmoid(d1 + d2)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.w1_l1.data.normal_()\n",
    "        self.w2_l1.data.normal_()\n",
    "        self.w1_l2.data.normal_(std=1 / np.sqrt(self.l1_dim))\n",
    "        self.w2_l2.data.normal_(std=1 / np.sqrt(self.l1_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28991d91",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ea866d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************Training Started********************\n",
      "\n",
      "Loss at Epoch 0 : 1.3793329000473022\n",
      "Loss at Epoch 1 : 1.368251085281372\n",
      "Loss at Epoch 2 : 1.3716557025909424\n",
      "Loss at Epoch 3 : 1.3684101104736328\n",
      "Loss at Epoch 4 : 1.3651847839355469\n",
      "Loss at Epoch 5 : 1.3630248308181763\n",
      "Loss at Epoch 6 : 1.3603675365447998\n",
      "Loss at Epoch 7 : 1.3538751602172852\n",
      "Loss at Epoch 8 : 1.3432443141937256\n",
      "Loss at Epoch 9 : 1.3299320936203003\n",
      "\n",
      "*******************Training Complete********************\n",
      "\n",
      "Test set Results:\n",
      "AUPRC:0.6621   AUCROC:0.7082   AP@50:0.6625\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 10\n",
    "\n",
    "# set training device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "settings = Setting(sp_rate=0.9, lr=0.01, prot_drug_dim=16, prot_dis_dim=16, n_drug_embed=48, n_dis_embed=48, n_hid1=32, n_hid2=16)\n",
    "model = DrugDiseaseGNN(settings, device)\n",
    "\n",
    "# initial optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=settings.lr)\n",
    "\n",
    "print(\"*******************Training Started********************\")\n",
    "print()\n",
    "\n",
    "# train model\n",
    "losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss, (prot_embeddings, embeddings1, embeddings2) = model()\n",
    "    print(\"Loss at Epoch\", e, \":\", loss.item())\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print()\n",
    "print(\"*******************Training Complete********************\")\n",
    "print()\n",
    "\n",
    "# evaluate on test set\n",
    "model.test()\n",
    "\n",
    "# save trained model\n",
    "torch.save(model, f'../saved_model/try2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddff20",
   "metadata": {},
   "source": [
    "## Visualizing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5f5d496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(losses)), losses, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5afc2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = prot_embeddings.detach().cpu().numpy()\n",
    "drugs = embeddings1.detach().cpu().numpy()\n",
    "diseases = embeddings2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b207ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings = dict()\n",
    "save_embeddings[\"proteins\"] = proteins\n",
    "save_embeddings[\"drugs\"] = drugs\n",
    "save_embeddings[\"diseases\"] = diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f849f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./embeddings.pkl', 'wb') as f:   # the whole dataset\n",
    "    pickle.dump(save_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7df8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4260 1269\n"
     ]
    }
   ],
   "source": [
    "count=total=0\n",
    "embeddingtype = diseases\n",
    "for i in range(len(embeddingtype)):\n",
    "    if(np.all(embeddingtype[i]==0)):\n",
    "        count+=1\n",
    "    else:\n",
    "        total+=1\n",
    "        \n",
    "print(count, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58ddf31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseases[4260+1268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ff05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrugDiseaseGNN(\n",
       "  (encoder): EndToEndEncoder(\n",
       "    (pp_encoder): PPEncoder(\n",
       "      (conv1): GATv2Conv(18505, 32, heads=1)\n",
       "      (conv2): GATv2Conv(32, 16, heads=1)\n",
       "      (Linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (hgcn1): CrossEdgeConv(16, 16\n",
       "    (hgcn2): CrossEdgeConv(16, 16\n",
       "  )\n",
       "  (decoder): NNDecoder()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
