{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27371980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.models import InnerProductDecoder\n",
    "import numpy as np\n",
    "from torch.nn import Parameter as Param, Linear\n",
    "from torch import nn\n",
    "from torch_geometric.nn.conv import GATv2Conv, MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "\n",
    "torch.manual_seed(29)\n",
    "np.random.seed(29)\n",
    "EPS = 1e-13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b14a75",
   "metadata": {},
   "source": [
    "## Custom defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2717745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auprc_auroc_ap(target_tensor, score_tensor):\n",
    "    y = target_tensor.detach().cpu().numpy()\n",
    "    pred = score_tensor.detach().cpu().numpy()\n",
    "    auroc, ap = metrics.roc_auc_score(y, pred), metrics.average_precision_score(y, pred)\n",
    "    y, xx, _ = metrics.precision_recall_curve(y, pred)\n",
    "    auprc = metrics.auc(xx, y)\n",
    "\n",
    "    return auprc, auroc, ap\n",
    "\n",
    "def get_range_list(edge_list):\n",
    "    tmp = []\n",
    "    s = 0\n",
    "    for i in edge_list:\n",
    "        tmp.append((s, s + i.shape[1]))\n",
    "        s += i.shape[1]\n",
    "    return torch.tensor(tmp)\n",
    "\n",
    "def negative_sampling(pos_edge_index, num_nodes, num_dis):\n",
    "\n",
    "    idx = (pos_edge_index[0] * num_nodes + pos_edge_index[1])\n",
    "    idx = idx.to(torch.device('cpu'))\n",
    "\n",
    "    perm = torch.tensor(np.random.choice(num_nodes*num_dis, idx.size(0)))\n",
    "    mask = torch.from_numpy(np.isin(perm, idx).astype(np.uint8))\n",
    "    rest = mask.nonzero().view(-1)\n",
    "\n",
    "    while rest.numel() > 0:\n",
    "        tmp = torch.tensor(np.random.choice(num_nodes*num_dis, rest.size(0)))\n",
    "        mask = torch.from_numpy(np.isin(tmp, idx).astype(np.uint8))\n",
    "        perm[rest] = tmp\n",
    "        rest = mask.nonzero().view(-1)\n",
    "    row, col = perm / num_nodes, perm % num_nodes\n",
    "    returnable = torch.stack([row, col], dim=0).long().to(pos_edge_index.device)\n",
    "    return returnable\n",
    "\n",
    "def typed_negative_sampling(pos_edge_index, num_nodes, num_dis, range_list):\n",
    "    \n",
    "    tmp = []\n",
    "    for start, end in range_list:\n",
    "        tmp.append(negative_sampling(pos_edge_index[:, start: end], num_nodes, num_dis))\n",
    "        \n",
    "    value = torch.cat(tmp, dim=1)\n",
    "    return value\n",
    "\n",
    "def process_edges(raw_edge_list, p=0.9):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    train_label_list = []\n",
    "    test_label_list = []\n",
    "\n",
    "    train_mask = np.random.binomial(1, p, raw_edge_list.shape[1])\n",
    "    test_mask = 1 - train_mask\n",
    "    train_set = train_mask.nonzero()[0]\n",
    "    test_set = test_mask.nonzero()[0]\n",
    "\n",
    "    train_list.append(raw_edge_list[:, train_set])\n",
    "    test_list.append(raw_edge_list[:, test_set])\n",
    "\n",
    "    train_label_list.append(torch.ones(2 * train_set.size, dtype=torch.long))\n",
    "    test_label_list.append(torch.ones(2 * test_set.size, dtype=torch.long))\n",
    "\n",
    "    train_range = get_range_list(train_list)\n",
    "    test_range = get_range_list(test_list)\n",
    "\n",
    "    train_edge_idx = torch.cat(train_list, dim=1)\n",
    "    test_edge_idx = torch.cat(test_list, dim=1)\n",
    "\n",
    "    train_et = torch.cat(train_label_list)\n",
    "    test_et = torch.cat(test_label_list)\n",
    "    \n",
    "    return train_edge_idx, train_et, train_range, test_edge_idx, test_et, test_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc6c45",
   "metadata": {},
   "source": [
    "## Custom Graph Convolution For Cross Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9dd29f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEdgeConv(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim,\n",
    "                 unique_source_num, unique_target_num,\n",
    "                 is_after_relu=True, is_bias=False, **kwargs):\n",
    "\n",
    "        super(CrossEdgeConv, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.unique_source_num = unique_source_num\n",
    "        self.unique_target_num = unique_target_num\n",
    "        self.is_after_relu = is_after_relu\n",
    "\n",
    "        self.weight = Param(torch.Tensor(in_dim, out_dim))\n",
    "\n",
    "        if is_bias:\n",
    "            self.bias = Param(torch.Tensor(out_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.is_after_relu:\n",
    "            self.weight.data.normal_(std=1/np.sqrt(self.in_dim))\n",
    "        else:\n",
    "            self.weight.data.normal_(std=2/np.sqrt(self.in_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, range_list):\n",
    "        return self.propagate(edge_index, x=x, range_list=range_list)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, range_list):\n",
    "        if self.bias:\n",
    "            aggr_out += self.bias\n",
    "\n",
    "        out = torch.matmul(aggr_out[self.unique_source_num:, :], self.weight)\n",
    "        assert out.shape[0] == self.unique_target_num\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}'.format(self.__class__.__name__, self.in_dim, self.out_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77e06c",
   "metadata": {},
   "source": [
    "## Integrated GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f60eb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Setting(object):\n",
    "    def __init__(self, sp_rate=0.9, lr=0.01, prot_drug_dim=16, prot_dis_dim = 16, n_drug_embed=64,\n",
    "                n_dis_embed=64, n_hid1=32, n_hid2=16) -> None:\n",
    "        super().__init__()\n",
    "        self.sp_rate = sp_rate\n",
    "        self.lr = lr\n",
    "        self.prot_drug_dim = prot_drug_dim\n",
    "        self.prot_dis_dim = prot_dis_dim\n",
    "        self.n_drug_embed = n_drug_embed\n",
    "        self.n_dis_embed = n_dis_embed\n",
    "        self.n_hid1 = n_hid1\n",
    "        self.n_hid2 = n_hid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1d154a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DrugDiseaseGNN(torch.nn.Module):\n",
    "    def __init__(self, settings:Setting, device, mod='cat', data_path='./final_data.pkl', ) -> None:\n",
    "        super().__init__()\n",
    "        self.mod = mod\n",
    "        self.device = device\n",
    "        self.settings = settings\n",
    "        self.data = self.__prepare_data(data_path, settings.sp_rate).to(device)\n",
    "        self.__prepare_model()\n",
    "\n",
    "\n",
    "    def __prepare_data(self, data_path, sp_rate):\n",
    "\n",
    "        with open(data_path, 'rb') as f:\n",
    "            data_dict = pickle.load(f)\n",
    "        data = Data.from_dict(data_dict)\n",
    "        \n",
    "        data.dd_train_idx, data.dd_train_et, data.dd_train_range, data.dd_test_idx, data.dd_test_et, data.dd_test_range = process_edges(data.dd_edge_index, p=sp_rate)\n",
    "        self.test_neg_index = typed_negative_sampling(data.dd_test_idx, data.n_drug, data.n_dis, data.dd_test_range)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __get_ndata__(self):\n",
    "        return self.data.n_drug_feat, self.data.n_drug, self.data.p_feat.shape[1], self.data.n_prot, self.data.n_dis_feat, self.data.n_dis\n",
    "\n",
    "    def __get_dimset__(self):\n",
    "        return self.settings.prot_drug_dim, self.settings.prot_dis_dim, self.settings.n_drug_embed, self.settings.n_dis_embed,self.settings.n_hid1, self.settings.n_hid2\n",
    "\n",
    "    def __prepare_model(self):\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        self.encoder = EndToEndEncoder(\n",
    "            self.device,\n",
    "            *self.__get_ndata__(), \n",
    "            *self.__get_dimset__()\n",
    "        ).to(self.device)\n",
    "\n",
    "        # decoder\n",
    "        \n",
    "#         self.decoder = MultiInnerProductDecoder(\n",
    "#             self.settings.n_hid2\n",
    "#         ).to(self.device)\n",
    "        \n",
    "        self.decoder = NNDecoder(\n",
    "            self.settings.n_hid2, self.settings.n_hid2,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        self.prot_embeddings, self.embeddings1, self.embeddings2 = self.encoder(self.data.d_feat, self.data.dis_feat, self.data.p_feat,                                       self.data.pp_train_indices, self.data.dp_edge_index, \n",
    "                                       self.data.dp_range_list, self.data.disp_edge_index, self.data.disp_range_list)\n",
    "\n",
    "        pos_index = self.data.dd_train_idx\n",
    "        neg_index = typed_negative_sampling(self.data.dd_train_idx, self.data.n_drug, self.data.n_dis, self.data.dd_train_range).type_as(pos_index)\n",
    "\n",
    "# Use with InnerProduct Decoder\n",
    "#         pos_score = self.decoder(self.embeddings1, self.embeddings2, pos_index, self.data.dd_train_et)\n",
    "#         neg_score = self.decoder(self.embeddings1, self.embeddings2, neg_index, self.data.dd_train_et)\n",
    "\n",
    "        pos_score = self.decoder(self.embeddings1, self.embeddings2, pos_index)\n",
    "        neg_score = self.decoder(self.embeddings1, self.embeddings2, neg_index)\n",
    "\n",
    "        pos_loss = -torch.log(pos_score + EPS).mean()\n",
    "        neg_loss = -torch.log(1 - neg_score + EPS).mean()\n",
    "        loss = pos_loss + neg_loss\n",
    "\n",
    "        return loss, (self.prot_embeddings, self.embeddings1, self.embeddings2)\n",
    "\n",
    "    def test(self, print_output=True):\n",
    "        \n",
    "        self.eval()\n",
    "        \n",
    "# Use with InnerProduct Decoder\n",
    "#         pos_score = self.decoder(self.embeddings1, self.embeddings2, self.data.dd_test_idx, self.data.dd_test_et)\n",
    "#         neg_score = self.decoder(self.embeddings1, self.embeddings2, self.test_neg_index, self.data.dd_test_et)\n",
    "\n",
    "        pos_score = self.decoder(self.embeddings1, self.embeddings2, self.data.dd_test_idx)\n",
    "        neg_score = self.decoder(self.embeddings1, self.embeddings2, self.test_neg_index)\n",
    "\n",
    "        return self.compute_auprc_auroc_ap_by_et(pos_score, neg_score, self.data.dd_test_range, print_output)\n",
    "\n",
    "    def compute_auprc_auroc_ap_by_et(self, pos_score, neg_score, dd_range, print_out):\n",
    "        \n",
    "        n_dd_et = dd_range.shape[0]\n",
    "        record = np.zeros((3, n_dd_et))     # auprc, auroc, ap\n",
    "        for i in range(dd_range.shape[0]):\n",
    "            [start, end] = dd_range[i]\n",
    "            p_s = pos_score[start: end]\n",
    "            n_s = neg_score[start: end]\n",
    "\n",
    "            pos_target = torch.ones(p_s.shape[0])\n",
    "            neg_target = torch.zeros(n_s.shape[0])\n",
    "\n",
    "            score = torch.cat([p_s, n_s])\n",
    "            target = torch.cat([pos_target, neg_target])\n",
    "\n",
    "            record[0, i], record[1, i], record[2, i] = auprc_auroc_ap(target, score)\n",
    "\n",
    "        if print_out:\n",
    "            [auprc, auroc, ap] = record.sum(axis=1) / n_dd_et\n",
    "\n",
    "            print('Test set Results:\\nAUPRC:{:0.4f}   AUCROC:{:0.4f}   AP@50:{:0.4f}'.format(auprc, auroc, ap))\n",
    "\n",
    "        return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e778f07",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40f6b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hid1=32, hid2=16):\n",
    "        super(PPEncoder, self).__init__()\n",
    "        self.out_dim = hid2\n",
    "\n",
    "        self.conv1 = GATv2Conv(in_dim, hid1)\n",
    "        self.conv2 = GATv2Conv(hid1, hid2)\n",
    "        self.Linear = Linear(hid2, hid2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.Linear(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class EndToEndEncoder(torch.nn.Module):   \n",
    "        \n",
    "    def __init__(\n",
    "                self, device, n_drug_feat, n_drug, n_prot_feat, n_prot, n_dis_feat, n_dis,\n",
    "                prot_drug_dim=16,\n",
    "                prot_dis_dim=16,\n",
    "                n_drug_embed=64,\n",
    "                n_dis_embed=64,\n",
    "                n_hid1=32, \n",
    "                n_hid2=16, \n",
    "                mod='cat'):\n",
    "\n",
    "        super(EndToEndEncoder, self).__init__()\n",
    "\n",
    "        self.out_dim = n_hid2\n",
    "        self.uni_num_drug = n_drug\n",
    "        self.uni_num_prot = n_prot\n",
    "        self.uni_num_dis = n_dis\n",
    "\n",
    "        # mod\n",
    "        self.mod = mod\n",
    "\n",
    "        # on pp-net\n",
    "        self.pp_encoder = PPEncoder(n_prot_feat)\n",
    "\n",
    "        # on pd-net\n",
    "        self.hgcn1 = CrossEdgeConv(self.pp_encoder.out_dim, prot_drug_dim, n_prot, n_drug)\n",
    "        self.hdrug = torch.zeros((self.uni_num_drug, self.pp_encoder.out_dim)).to(device)\n",
    "        \n",
    "        # on pdis-net\n",
    "        self.hgcn2 = CrossEdgeConv(self.pp_encoder.out_dim, prot_dis_dim, n_prot, n_dis)\n",
    "        self.hdis = torch.zeros((self.uni_num_dis, self.pp_encoder.out_dim)).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x_drug, x_dis, x_prot, \n",
    "                pp_edge_index, dp_edge_index, dp_range_list, disp_edge_index, disp_range_list):\n",
    "        \n",
    "        # pp-net\n",
    "        \n",
    "        x_prot = self.pp_encoder(x_prot, pp_edge_index)\n",
    "        \n",
    "         #pdis-net\n",
    "        x_dis = torch.cat((x_prot, self.hdis))\n",
    "        x_dis = self.hgcn2(x_dis, disp_edge_index, disp_range_list)\n",
    "\n",
    "        # pd-net\n",
    "        x_drug = torch.cat((x_prot, self.hdrug))\n",
    "        x_drug = self.hgcn1(x_drug, dp_edge_index, dp_range_list)\n",
    "        \n",
    "       \n",
    "        \n",
    "        return (x_prot, x_drug, x_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0898e7c",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cb0f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInnerProductDecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim):\n",
    "        super(MultiInnerProductDecoder, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.weight = Param(torch.Tensor(1, in_dim))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, z2, z1, edge_index, sigmoid=True):\n",
    "\n",
    "        value = (z1[edge_index[0]] * z2[edge_index[1]] * self.weight[0]).sum(dim=1)\n",
    "        return torch.sigmoid(value)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.normal_(std=1/np.sqrt(self.in_dim))\n",
    "\n",
    "\n",
    "class NNDecoder(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, in_dim_drug, in_dim_dis, l1_dim=16):\n",
    "\n",
    "        super(NNDecoder, self).__init__()\n",
    "        self.l1_dim = l1_dim\n",
    "\n",
    "        # for drug \n",
    "        self.w1_l1 = Param(torch.Tensor(in_dim_drug, l1_dim))\n",
    "        self.w1_l2 = Param(torch.Tensor(1, l1_dim))  \n",
    "\n",
    "        # for disease\n",
    "        self.w2_l1 = Param(torch.Tensor(in_dim_dis, l1_dim))\n",
    "        self.w2_l2 = Param(torch.Tensor(1, l1_dim))  \n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, z2, z1, edge_index):\n",
    "        \n",
    "        # layer 1\n",
    "        d1 = torch.matmul(z1[edge_index[0]], self.w1_l1)\n",
    "        d2 = torch.matmul(z2[edge_index[1]], self.w2_l1)\n",
    "        d1 = F.relu(d1, inplace=True)\n",
    "        d2 = F.relu(d2, inplace=True)\n",
    "\n",
    "        # layer 2\n",
    "        d1 = (d1 * self.w1_l2[0]).sum(dim=1)\n",
    "        d2 = (d2 * self.w2_l2[0]).sum(dim=1)\n",
    "\n",
    "        return torch.sigmoid(d1 + d2)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.w1_l1.data.normal_()\n",
    "        self.w2_l1.data.normal_()\n",
    "        self.w1_l2.data.normal_(std=1 / np.sqrt(self.l1_dim))\n",
    "        self.w2_l2.data.normal_(std=1 / np.sqrt(self.l1_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28991d91",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1ea866d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************Training Started********************\n",
      "\n",
      "Loss at Epoch 0 : 1.4441848993301392\n",
      "Loss at Epoch 1 : 1.3941254615783691\n",
      "Loss at Epoch 2 : 1.4022765159606934\n",
      "Loss at Epoch 3 : 1.389384150505066\n",
      "Loss at Epoch 4 : 1.3835985660552979\n",
      "Loss at Epoch 5 : 1.3865864276885986\n",
      "Loss at Epoch 6 : 1.3844585418701172\n",
      "Loss at Epoch 7 : 1.3791697025299072\n",
      "Loss at Epoch 8 : 1.377157211303711\n",
      "Loss at Epoch 9 : 1.3707520961761475\n",
      "Loss at Epoch 10 : 1.3701016902923584\n",
      "Loss at Epoch 11 : 1.3585596084594727\n",
      "Loss at Epoch 12 : 1.3487894535064697\n",
      "Loss at Epoch 13 : 1.330991268157959\n",
      "Loss at Epoch 14 : 1.3096613883972168\n",
      "Loss at Epoch 15 : 1.2863224744796753\n",
      "Loss at Epoch 16 : 1.252882957458496\n",
      "Loss at Epoch 17 : 1.2181190252304077\n",
      "Loss at Epoch 18 : 1.1786653995513916\n",
      "Loss at Epoch 19 : 1.1366705894470215\n",
      "Loss at Epoch 20 : 1.102649211883545\n",
      "Loss at Epoch 21 : 1.0719237327575684\n",
      "Loss at Epoch 22 : 1.0443100929260254\n",
      "Loss at Epoch 23 : 1.019347071647644\n",
      "Loss at Epoch 24 : 0.9930118322372437\n",
      "Loss at Epoch 25 : 0.9744449257850647\n",
      "Loss at Epoch 26 : 0.9510953426361084\n",
      "Loss at Epoch 27 : 0.9350632429122925\n",
      "Loss at Epoch 28 : 0.921087920665741\n",
      "Loss at Epoch 29 : 0.9038574695587158\n",
      "Loss at Epoch 30 : 0.8895342350006104\n",
      "Loss at Epoch 31 : 0.8757516145706177\n",
      "Loss at Epoch 32 : 0.8651983737945557\n",
      "Loss at Epoch 33 : 0.8492372632026672\n",
      "Loss at Epoch 34 : 0.8333643674850464\n",
      "Loss at Epoch 35 : 0.8211280703544617\n",
      "Loss at Epoch 36 : 0.8138539791107178\n",
      "Loss at Epoch 37 : 0.8010799884796143\n",
      "Loss at Epoch 38 : 0.7926373481750488\n",
      "Loss at Epoch 39 : 0.7813624143600464\n",
      "Loss at Epoch 40 : 0.7719646692276001\n",
      "Loss at Epoch 41 : 0.7666090726852417\n",
      "Loss at Epoch 42 : 0.7558225393295288\n",
      "Loss at Epoch 43 : 0.7512555718421936\n",
      "Loss at Epoch 44 : 0.7441864013671875\n",
      "Loss at Epoch 45 : 0.7351312041282654\n",
      "Loss at Epoch 46 : 0.7297626733779907\n",
      "Loss at Epoch 47 : 0.7254325151443481\n",
      "Loss at Epoch 48 : 0.7272923588752747\n",
      "Loss at Epoch 49 : 0.7337087392807007\n",
      "Loss at Epoch 50 : 0.7243165373802185\n",
      "Loss at Epoch 51 : 0.703555703163147\n",
      "Loss at Epoch 52 : 0.7128630876541138\n",
      "Loss at Epoch 53 : 0.7016873359680176\n",
      "Loss at Epoch 54 : 0.6957952976226807\n",
      "Loss at Epoch 55 : 0.6961902379989624\n",
      "Loss at Epoch 56 : 0.6830846071243286\n",
      "Loss at Epoch 57 : 0.6896572113037109\n",
      "Loss at Epoch 58 : 0.6760148406028748\n",
      "Loss at Epoch 59 : 0.6766231060028076\n",
      "Loss at Epoch 60 : 0.6718544363975525\n",
      "Loss at Epoch 61 : 0.6693655252456665\n",
      "Loss at Epoch 62 : 0.6739540100097656\n",
      "Loss at Epoch 63 : 0.6658281087875366\n",
      "Loss at Epoch 64 : 0.6679089069366455\n",
      "Loss at Epoch 65 : 0.6598110198974609\n",
      "Loss at Epoch 66 : 0.6608647108078003\n",
      "Loss at Epoch 67 : 0.6541686654090881\n",
      "Loss at Epoch 68 : 0.6562685966491699\n",
      "Loss at Epoch 69 : 0.6491154432296753\n",
      "Loss at Epoch 70 : 0.654809296131134\n",
      "Loss at Epoch 71 : 0.6485727429389954\n",
      "Loss at Epoch 72 : 0.6523728370666504\n",
      "Loss at Epoch 73 : 0.646864116191864\n",
      "Loss at Epoch 74 : 0.647058367729187\n",
      "Loss at Epoch 75 : 0.6392893195152283\n",
      "Loss at Epoch 76 : 0.6408956050872803\n",
      "Loss at Epoch 77 : 0.6361386179924011\n",
      "Loss at Epoch 78 : 0.6388909816741943\n",
      "Loss at Epoch 79 : 0.6354806423187256\n",
      "Loss at Epoch 80 : 0.635520339012146\n",
      "Loss at Epoch 81 : 0.6345807313919067\n",
      "Loss at Epoch 82 : 0.6307961344718933\n",
      "Loss at Epoch 83 : 0.6307244300842285\n",
      "Loss at Epoch 84 : 0.6313954591751099\n",
      "Loss at Epoch 85 : 0.6241812705993652\n",
      "Loss at Epoch 86 : 0.6258829832077026\n",
      "Loss at Epoch 87 : 0.6227855682373047\n",
      "Loss at Epoch 88 : 0.6242970824241638\n",
      "Loss at Epoch 89 : 0.6228856444358826\n",
      "Loss at Epoch 90 : 0.6217204332351685\n",
      "Loss at Epoch 91 : 0.6198817491531372\n",
      "Loss at Epoch 92 : 0.6291897892951965\n",
      "Loss at Epoch 93 : 0.6267487406730652\n",
      "Loss at Epoch 94 : 0.6288540959358215\n",
      "Loss at Epoch 95 : 0.6144417524337769\n",
      "Loss at Epoch 96 : 0.6320388317108154\n",
      "Loss at Epoch 97 : 0.6515017747879028\n",
      "Loss at Epoch 98 : 0.6353824734687805\n",
      "Loss at Epoch 99 : 0.6360723972320557\n",
      "\n",
      "*******************Training Complete********************\n",
      "\n",
      "Test set Results:\n",
      "AUPRC:0.9053   AUCROC:0.9282   AP@50:0.9053\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 100\n",
    "\n",
    "# set training device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "settings = Setting(sp_rate=0.9, lr=0.01, prot_drug_dim=16, prot_dis_dim=16, n_drug_embed=48, n_dis_embed=48, n_hid1=32, n_hid2=16)\n",
    "model = DrugDiseaseGNN(settings, device)\n",
    "\n",
    "# initial optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=settings.lr)\n",
    "\n",
    "print(\"*******************Training Started********************\")\n",
    "print()\n",
    "\n",
    "# train model\n",
    "losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss, (prot_embeddings, embeddings1, embeddings2) = model()\n",
    "    print(\"Loss at Epoch\", e, \":\", loss.item())\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print()\n",
    "print(\"*******************Training Complete********************\")\n",
    "print()\n",
    "\n",
    "# evaluate on test set\n",
    "model.test()\n",
    "\n",
    "# save trained model\n",
    "torch.save(model, f'../saved_model/try2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f08e8957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrugDiseaseGNN(\n",
       "  (encoder): EndToEndEncoder(\n",
       "    (pp_encoder): PPEncoder(\n",
       "      (conv1): GATv2Conv(18505, 32, heads=1)\n",
       "      (conv2): GATv2Conv(32, 16, heads=1)\n",
       "      (Linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (hgcn1): CrossEdgeConv(16, 16\n",
       "    (hgcn2): CrossEdgeConv(16, 16\n",
       "  )\n",
       "  (decoder): NNDecoder()\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d177256",
   "metadata": {},
   "source": [
    "## Visualizing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5f5d496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmKUlEQVR4nO3de7yVY/7/8denvTtTUWmoqJQII2ZLyKkcig6YSJPkMHKaMExiGId+ZsYhxDgfYyjTONUUcgqhZEuTHKJSStFWkVJRfX5/XPf+tuxp73btvfa91rrfz8djPVrrvu+11ufeq8d6r/u67vu6zN0REZHkqhZ3ASIiEi8FgYhIwikIREQSTkEgIpJwCgIRkYRTEIiIJJyCQCRHmNnpZvZW3HVI9lEQSMYys3lmdmTcdWwNMzvczDaY2coStwPjrk2kpPy4CxDJYYvcvVncRYhsjo4IJOuYWU0zG25mi6LbcDOrGa1rZGbjzOw7M1tmZpPMrFq0boiZfWVmP5jZLDPrsonXPsDMvjazvJRlJ5jZjOh+BzMrNLMVZvaNmd26lfvwupn93cymRq81xsy2T1nf08w+ivbjdTPbI2VdczN7xsyKzGypmd1Z4rWHmdlyM/vCzLqlLD/dzOZG+/+FmfXbmtol9ygIJBtdCXQE2gP7AB2Aq6J1lwILgcZAE+DPgJtZW+APwP7uvi1wDDCv5Au7+7vAKqBzyuLfASOj+7cDt7t7PWBXYHQF9uM04ExgR2AdcAeAme0GjAIujvbjeeA/ZlYjCqhxwHygBdAUeDLlNQ8AZgGNgJuAhyyoG71+t2j/DwKmV6B2ySEKAslG/YCh7r7E3YuA64D+0bqfCV+su7j7z+4+ycOAWuuBmkA7M6vu7vPcfU4prz8K6AtgZtsCx0bLil+/tZk1cveV7j6ljDp3in7Rp97qpqz/p7vPdPdVwF+Ak6Mv+j7AeHd/2d1/BoYBtQlf3h2AnYDB7r7K3de4e2oH8Xx3f8Dd1wOPRn+LJtG6DcBeZlbb3Re7+0dl1C4JoiCQbLQT4RdxsfnRMoCbgdnAS1EzyOUA7j6b8Av7WmCJmT1pZjuxaSOBE6PmphOBae5e/H5nAbsBn5rZe2bWvYw6F7l7gxK3VSnrF5TYh+qEX/K/2D933xBt2xRoTviyX1fKe36d8rwfo7vbRO/bBzgXWGxm481s9zJqlwRREEg2WgTskvJ452gZ7v6Du1/q7q2AnsAlxX0B7j7S3TtFz3Xgxk29uLt/TPgi7sYvm4Vw98/dvS+wQ/T8p0r8yt8SzUvsw8/AtyX3z8ws2vYrQiDsbGZbfKKHu09w96MIRwmfAg9sZd2SYxQEkumqm1mtlFs+oZnmKjNrbGaNgKuBxwHMrLuZtY6+PL8nNAltMLO2ZtY5+pW/BlhNaCopzUjgIuBQ4N/FC83sVDNrHP1K/y5aXNbrlOVUM2tnZnWAocBTUZPOaOA4M+tiZtUJ/R5rgXeAqcBi4AYzqxv9TQ7e3BuZWRMz6xWF1lpgZQXqlhyjIJBM9zzhS7v4di1wPVAIzAA+BKZFywDaAK8QvugmA3e7+0RC/8ANhF/cXxN+0V9RxvuOAg4DXnP3b1OWdwU+MrOVhI7jU9x9dSmvsdMmriP4bcr6fwIjonpqARcCuPss4FTgH1G9PYAe7v5TFBQ9gNbAl4SO8T5l7EexasAlhKONZdG+nVeO50kCmCamEal6ZvY68Li7Pxh3LSI6IhARSTgFgYhIwqlpSEQk4XREICKScFk36FyjRo28RYsWcZchIpJV3n///W/dvfGm1mVdELRo0YLCwsK4yxARySpmNr+0dWoaEhFJOAWBiEjCKQhERBJOQSAiknAKAhGRhFMQiIgknIJARCThkhMEM2fCpZfC6tJGDBYRSabkBMH8+XDrrTB5ctyViIhklOQEwSGHQF4evPZa3JWIiGSU5ARBvXqw//4KAhGREpITBACdO8PUqfDDD3FXIiKSMZIXBOvXw6RJcVciIpIxkhUEBx0ENWqoeUhEJEWygqB27RAGCgIRkf+TrCCA0Dw0fTosXRp3JSIiGSFtQWBmD5vZEjObuZnt9jezdWbWO121/ELnzuAOb7xRJW8nIpLp0nlEMALoWtYGZpYH3Ai8lMY6fmn//aFu3Y3NQ0uXwvDhUFRUZSWIiGSStAWBu78JLNvMZoOAp4El6arjf9SoES4ue/VVePxx2H13+OMfw5GCwkBEEii2PgIzawqcANxTjm0HmlmhmRUWVcaXdefO8Omn0L8/7Lor3HcfzJ6tMBCRRIqzs3g4MMTdN2xuQ3e/390L3L2gcePGFX/n3/4W9tkH/vEPePttGDgQxo3bGAaffVbx9xARyRL5Mb53AfCkmQE0Ao41s3Xu/lza37lVq3DmUKouXUIY9OwZmot69ICLLoKffw5hMWUKbLMN7LkntGsHhx8OO+6Y9lJFRNIttiBw95bF981sBDCuSkKgLF26wNy5cNddcPfdMHZsWF6tGuy9N3z5ZVi2fn0YwO744+G888JRRAg0EZGsk7YgMLNRwOFAIzNbCFwDVAdw93vT9b4V1qQJDB0Kl18O//kPNGwIBxwA224b1q9dC598Ak88AQ8/DE8/HQa02333cDviCOjXD6pXj3c/RETKydw97hq2SEFBgRcWFsZdRrBmTQiCyZNh1iz4+GNYtAhatIA//xkGDAhnKYmIxMzM3nf3gk2tS96VxZWpVq3w6//OO+Hll2HhQhg/HnbYIXRA16oVjhaaNg19Dt9+G3fFIiL/I87O4txjBsceC926wUsvwVtvwcqV8N13MGoUdOoEL74YjhhERDKEmoaqyqRJ4YykWrXghRegffu4KxKRBFHTUCY45JBwhJCfH44Mnnwy7opERAAFQdXac89wPUL79tC3L5x/fuhwFhGJkYKgqjVtChMnwuDBcM894Uhh5cq4qxKRBFMQxKF6dbjppnDq6fvvw6BBcVckIgmmIIjTiSfCVVfBiBHhrCIRkRgoCOJ29dVh+sxzzw3DW4iIVDEFQdzy88NwFWbwu9/BunVxVyQiCaMgyAQtWsC998K774arlEVEqpCCIFP06QNdu4amokWL4q5GRBJEQZApzOCOO8Lopn/6U9zViEiCKAgySZs2MGRIOIPotdfirkZEEkJBkGmuuAJatoQLLoCffoq7GhFJAAVBpqldOzQRffppuPJYRCTNFASZ6LjjwrSZQ4eGIaxFRNJIQZCJzGDYMFi+HP72t7irEZEcpyDIVO3bQ//+oZlo3ry4qxGRHKYgyGTXXx+ODq68Mu5KRCSHKQgyWfPmcMklMHIkTJ8edzUikqMUBJlu8OAwveV998VdiYjkKAVBpmvQAHr3DkcFP/4YdzUikoMUBNngrLNgxQp45pm4KxGRHKQgyAaHHgqtWsFDD8VdiYjkIAVBNqhWDc48E15/HebMibsaEckxCoJscfrpIRAeeSTuSkQkxygIskXTpmG+ghEjYP36uKsRkRyiIMgmZ50FX30FEybEXYmI5BAFQTbp3h0aNYJHH427EhHJIQqCbFKjBvTtC2PGhAHpREQqgYIg2wwYEKazHD067kpEJEcoCLLNfvvBnnuqeUhEKo2CINuYhaOCyZPhs8/irkZEcoCCIBudemq4puCxx+KuRERygIIgG+24Ixx9dAiCDRvirkZEspyCIFsNGAALFsDEiXFXIiJZTkGQrXr1gm22gX/9K+5KRCTLpS0IzOxhM1tiZjNLWd/PzGaY2Ydm9o6Z7ZOuWnJS7drhArNnn4V16+KuRkSyWDqPCEYAXctY/wVwmLvvDfw/4P401pKbeveGb7+FSZPirkREsljagsDd3wSWlbH+HXcvvjx2CtAsXbXkrG7doE4deOqpuCsRkSyWKX0EZwEvlLbSzAaaWaGZFRYVFVVhWRmuTp0QBs88oxFJRWSrxR4EZnYEIQiGlLaNu9/v7gXuXtC4ceOqKy4b9O4NX38N77wTdyUikqViDQIz+zXwINDL3ZfGWUvWOu44qFkTnn467kpEJEvFFgRmtjPwDNDf3TVWwtbadtswYc3TT+viMhHZKuk8fXQUMBloa2YLzewsMzvXzM6NNrkaaAjcbWbTzawwXbXkvN69YeFCmDo17kpEJAvlp+uF3b3vZtb/Hvh9ut4/UXr0gOrVw1FBx45xVyMiWSb2zmKpBPXrwxFHwNixcVciIllIQZArevUKw1J/+mnclYhIllEQ5IoePcK/Y8bEW4eIZB0FQa5o3jzMXqbmIRHZQgqCXNKrV5i57Jtv4q5ERLKIgiCX9OwJ7jBuXNyViEgWURDkkn32gV12UT+BiGwRBUEuMQtHBS+/DD/+GHc1IpIlFAS5pmdPWLMmhIGISDkoCHLNYYdBgwaao0BEyk1BkGuqV4eTTw7DTaxYEXc1IpIFFAS56MwzYfVqGD067kpEJAsoCHJRhw6wxx7wyCNxVyIiWUBBkIvM4Iwzwqxls2bFXY2IZDgFQa7q3x/y8mDEiLgrEZEMpyDIVb/6VZjY/rHHNLG9iJRJQZDLzjgDFi2Cl16KuxIRyWAKglzWvTs0agQPPhh3JSKSwRQEuaxGjXAq6ZgxYU5jEZFNUBDkunPPhQ0b4L774q5ERDKUgiDXtWwZmojuvx/Wro27GhHJQAqCJLjgAliyJAw7ISJSgoIgCY46Ctq0gbvuirsSEclACoIkqFYNzj8/XGn8wQdxVyMiGUZBkBSnnw516sCdd8ZdiYhkGAVBUjRoAAMGwOOPh4vMREQiCoIk+dOfYN06GD487kpEJIOUKwjMrK6ZVYvu72ZmPc2senpLk0rXqhX06QP33gvffRd3NSKSIcp7RPAmUMvMmgIvAf2BEekqStLossvghx/gnnvirkREMkR5g8Dc/UfgROBudz8J2DN9ZUnatG8PXbuG5qHVq+OuRkQyQLmDwMwOBPoB46NleekpSdLu8svDBWaaq0BEKH8QXAxcATzr7h+ZWStgYtqqkvQ69FDo2BFuvBF++inuakQkZuUKAnd/w917uvuNUafxt+5+YZprk3Qxg2uvhfnz4aGH4q5GRGJW3rOGRppZPTOrC8wEPjazwektTdLq6KOhUye4/nr1FYgkXHmbhtq5+wrgeOAFoCXhzCHJVmYhBBYt0hlEIglX3iCoHl03cDww1t1/BjxtVUnVOOywMCDd3/8eTikVkUQqbxDcB8wD6gJvmtkuwIp0FSVV6Prr4dtv4Y474q5ERGJi7lv3w97M8t19XSXXs1kFBQVeWFhY1W+b23r2hEmTYN48qF8/7mpEJA3M7H13L9jUuvJ2Ftc3s1vNrDC63UI4OpBccM01YcgJzVcgkkjlbRp6GPgBODm6rQAeKesJZvawmS0xs5mlrDczu8PMZpvZDDPbb0sKl0r0m9/AscfCrbfCypVxVyMiVay8QbCru1/j7nOj23VAq808ZwTQtYz13YA20W0goFNX4vSXv8DSpTqDSCSByhsEq82sU/EDMzsYKPPkc3d/E1hWxia9gMc8mAI0MLMdy1mPVLaOHcMZRMOGwY8/xl2NiFSh8gbBucBdZjbPzOYBdwLnVPC9mwILUh4vjJb9DzMbWNw/UVRUVMG3lVJdfXUYg+j+++OuRESqUHmHmPivu+8D/Br4tbvvC3ROa2W/fP/73b3A3QsaN25cVW+bPJ06weGHww03wLKyDuZEJJds0Qxl7r4iusIY4JIKvvdXQPOUx82iZRKnW24JfQUXXBB3JSJSRSoyVaVV8L3HAqdFZw91BL5398UVfE2pqP32CwPSPfkkjBoVdzUiUgUqEgRlXolmZqOAyUBbM1toZmeZ2blmdm60yfPAXGA28ABwfgVqkco0ZAgceCCcfz4sWLD57UUkq+WXtdLMfmDTX/gG1C7rue7edzPrHVD7QybKz4fHHguzmZ1xBrz8chikTkRyUplHBO6+rbvX28RtW3cvM0Qky7VuDTffDK++Cs88E3c1IpJGFWkaklw3cCDstVdoKtJMZiI5S0EgpcvLg5tugjlz4N57465GRNJEQSBl69oVjjwSrrsuDEwnIjlHQSBlMwt9BcuXhwlsRCTnKAhk89q3h/79YfhwmD495mJEpLIpCKR8broJGjeGE04IM5qJSM5QEEj5NGkCzz4LixdDnz6wrsonpxORNFEQSPntv38YmfS112Dw4LirEZFKoovCZMucdhpMmxb6C1q31uB0IjlAQSBbbtgw+OILGDQItt8e+pY5moiIZDg1DcmWy88Po5Meemg4QnjhhbgrEpEKUBDI1qldG8aMgb33ht/+NjQXiUhWUhDI1qtfH158ERo2hJNPhu+/j7siEdkKCgKpmB12CBPYzJsHZ58NXuY0FSKSgRQEUnGdOsFf/wr//rcGpxPJQgoCqRyDB0O3bnDxxfDuu3FXIyJbQEEglaNatTCrWbNm0L07fPZZ3BWJSDkpCKTyNGoEEyaEEUuPOSYMRyEiGU9BIJWrdWt4/nkoKgpNRTqTSCTjKQik8hUUhHmOP/oIevSAH3+MuyIRKYOCQNLj6KPh8cfhrbegd2/NeSySwRQEkj59+oTTSV94IQxFsX593BWJyCZo0DlJr4EDw1zHQ4aEOQwefRTq1o27KhFJoSCQ9LvssjBQ3eDBMHt2GKNol13irkpEImoakqpxySUwfnwYiqKgQBediWQQBYFUna5dQwDUqwc9e8KCBXFXJCIoCKSqtW0L48bB6tVw/PHhXxGJlYJAqt4ee8ATT8AHH2jEUpEMoCCQePToAUOHhkC45Za4qxFJNAWBxOfKK8PsZkOGhDGKRCQWCgKJjxmMGAF77gmnnAKffx53RSKJpCCQeG2zTbiuIC8PevWCFSvirkgkcRQEEr+WLcPsZp99BieeCKtWxV2RSKIoCCQzHHEEPPQQTJwYrjfQ8NUiVUZBIJljwAAYNQqmTIEuXWDp0rgrEkkEBYFklpNPhueeg5kzYd99YeRIXWcgkmYKAsk8xx0Hr78epr7s1w8OPBCmTo27KpGcpSCQzNSxIxQWhtNLFyyAQw4JU2CKSKVLaxCYWVczm2Vms83s8k2s39nMJprZB2Y2w8yOTWc9kmWqVQv9Bh9+CHvtBSecEEYwFZFKlbYgMLM84C6gG9AO6Gtm7UpsdhUw2t33BU4B7k5XPZLFtt8eXnkFfv3rEAZjx8ZdkUhOSecRQQdgtrvPdfefgCeBXiW2caBedL8+sCiN9Ug22247ePnl0IHcqxcMGgQrV8ZdlUhOSGcQNAVSB5xfGC1LdS1wqpktBJ4HBm3qhcxsoJkVmllhUVFROmqVbNCgAbz2Glx4Idx1V2gueuWVuKsSyXpxdxb3BUa4ezPgWOCfZvY/Nbn7/e5e4O4FjRs3rvIiJYPUrQu33w6TJkGtWnD00TB8eNxViWS1dAbBV0DzlMfNomWpzgJGA7j7ZKAW0CiNNUmuOPhgmDYtTG7zxz/CRRfB+vVxVyWSldIZBO8BbcyspZnVIHQGl+zl+xLoAmBmexCCQG0/Uj516oQxii6+GO64IwxpraEpRLZY2oLA3dcBfwAmAJ8Qzg76yMyGmlnPaLNLgbPN7L/AKOB0d11GKlsgLw9uuy00D40bFzqTdfGZyBaxbPveLSgo8MLCwrjLkEz0zjvQty8sWhRmP7voonDUICKY2fvuXrCpdXF3FotUnoMOgunTQ7/Bn/8MzZrBpZfC7NlxVyaS0RQEklu22w5Gjw5jFR11VOg7aNsWhg3T4HUipVAQSO4xg8MOg3/9C778Mkx2M3gw/P738NNPcVcnknEUBJLbdtwxBMLVV8PDD8ORR8LkyTo6EEmhIJDcV60aXHddmPRm2rTQl7DrrnDVVbB4cdzVicROQSDJccop4YyiRx+FNm3g73+H1q3hmmvghx/irk4kNgoCSZZ69eC002DCBPjsM+jePZxq2rp1aEISSSAFgSTXrruGL/8pU6BFi3DEcOqp8N13cVcmUqUUBCIHHABvvx36EZ58Msx7MGpU+c8wKiqCr0oOoyWSPRQEIgD5+eHMonfegW22gd/9DnbeGf7yF/jii00/Z/HiMM7RzjvDbrvBI4/obCTJShpiQqSkDRvgpZfg7rvD+EXuUFAAJ58MO+wAn38On34a1q1bB/37w7x54SK2U06Be++F+vXj3guRXyhriAkFgUhZvvwyXKk8ejS8915YlpcX+hSOOAIuvzz0NaxfDzfcEM5A2mMPKCyEmjVjLV0klYJApDLMnw9r14YQqFFj09uMHRum0rzuutDUJJIhNOicSGXYZZfQF1BaCAD07Al9+sDf/haakIr9+CN89FH6axTZCgoCkcp2222hWei880L/wrRpYZ6EvfYKF7Fl2VG45D4FgUhl23HH8IX/6qthfoSOHWHVKujRIwyPffbZ8PPPcVcp8n8UBCLpcM450KFDuGCte3eYMQOeew6uvBIeegi6dQvLRDJAftwFiOSkvDx49ln44AM49tgwNDbA9deHs4wGDYJ99oFjjoHzzw9DX6xZE5qUDjssDJQnUkV01pBIHJYtC9cb3HEHfPPNL9edcQY8+KDCQCqVzhoSyTTbbx/6C+bNC30JEyeGeRKuuCJcoXzOOeHCNnd47TU46SR44424q5YcpaYhkTjVqgWdO298fMABoRnpb38Lp5x+9VUIADN44QV45ZXQ+SxSiXREIJJJzEI/wpAhMHIkzJoFt98Oc+bAr36lTmZJC/URiGQi99BU1L491KkTls2bB4ccEkZFPe00WLkynJbavj306wdNmsRYsGQ6DTEhkitmzQpHBV9/HUZJrVEjNB/l5UHXruFU1X33hb33DsHxxBNhaO369eEf/4CDD457DyQmZQWB+ghEsknbtjB37i+XffIJPPYYPP44jB8flpmFo4pq1aBLlxAgnTqFTujzzw+v8fHH4Wjj3HNDX4Uklo4IRHKFexgtddo0mD4dGjYMQ2f/6lehGemaa2D48HA2Uqo2bcKprKmd1pJz1DQkIsGMGeHWti3svnuYpvO880JndOfOYTjtoqLQ1HTxxaEvIl8NB7lAQSAipVu9OpypNHYsbLcdNG4c+hemTQujrQ4aBMuXh6akJUtg4MBwpFF8tfSyZfD886H/oWXLWHdFSqcgEJEt4w5jxoSpOmfODMtatAhHCnPmhOsdhgyBl1+GRx8N1zzk5YWzly67LATHuHHhYrh27UKY/OY3se5SVli9GoYOhQEDwhFbJVIQiMjW2bAhzKvQrBnUrRuajh57DK66ChYtCmctnXpqaEIaMyb0NaxeHZ6bnx8G3psxI/RRHHhgmPJz3bpw69QpPFdDaWw0eDAMGxbGo3rvvXCEVkkUBCJSuVatCvM6H3TQL69fKCqCf/4Tdt4ZjjoqnLb6/fcwYgTcd1847TU/PwTM0qXhKum77w6nvLqHZqYaNWDbbWPbtdhMmRKa17p0CfNfd+4czgLLy6uUl1cQiEhmcQ9HFoMHh0Bo2xYWLAhHDjVrhuk+TzstjNBaWAhTp4bmpkMPDV+QuXbx3Jo1IQxXrQpNcU8+GU71veKKMNwIhL9Z8SnBW0FBICKZ6bvvQkf155+HPohddgkd1SNHhoAolp8frnlYsSI8btFi49lMeXmhCaVhw3Cq7BFHhIvrGjas2n2piMsvhxtvhAkT4Oijw7JzzoH77w/7+sMPYd8HD4a//nWr3kJBICLZ5aef4MUXYf780K/Qvn1oMpo2LYzWWjzeklnob1i+PATH/Pnh32rVYL/9QkAU/4JetSp8ma5ZA717hy/fdDRBLVsG774bOntbtAg1btgQAm7NmtB5nuqdd8LQIWeeCQ88sHH52rWhL+abb0Kd9eqFkCsOii2kIBCRZNiwITQljR8Pb74ZvkyLh/OuW3fjBEATJsAOO8B114UL6ubODV/UO+0UvpT32isEyNq1YQgPs7CuZs2y3/+VV0KT1uLF4XH9+qGjfe7cjZ3ot98OF14Y7i9fHkIuPz+EXP366frLaIgJEUmIatXCmUodOpS93dSpcOml4WK61OcWX3XdoAHUrh06t1N/LO+wQwiEJk3CrVkzaN063MaNg5tvDv0d990XwuCDD2DhwvArvl27sM3FF4cmrJNOgt//Ppx99fbbaQ2BzVEQiEjydOgQjhjefDN80bdqBU2bhg7rN98MX8zr14ezn5o3D89ZuDCsX7w4NNd88kn4El+3buPrDhwIt922ccTYkvr1C6HQv384enjmmRAemwuuNFPTkIjI1lq3LvRLzJ4dRoMtz+iuy5eHayg+/jh0ao8fXyXXUsQ2VaWZdTWzWWY228wuL2Wbk83sYzP7yMxGprMeEZFKlZ8fLv465pjyD/G93XahI/zSS8MptBlwQV3amobMLA+4CzgKWAi8Z2Zj3f3jlG3aAFcAB7v7cjPbIV31iIhkjObNwxXEGSKdUdQBmO3uc939J+BJoFeJbc4G7nL35QDuviSN9YiIyCakMwiaAgtSHi+MlqXaDdjNzN42sylm1nVTL2RmA82s0MwKi4qK0lSuiEgyxd04lQ+0AQ4H+gIPmFmDkhu5+/3uXuDuBY0bN67aCkVEclw6g+AroHnK42bRslQLgbHu/rO7fwF8RggGERGpIukMgveANmbW0sxqAKcAY0ts8xzhaAAza0RoKioxIauIiKRT2oLA3dcBfwAmAJ8Ao939IzMbamY9o80mAEvN7GNgIjDY3Zdu+hVFRCQddEGZiEgCxHZBmYiIZL6sOyIwsyJg/lY+vRHwbSWWky2SuN9J3GdI5n4ncZ9hy/d7F3ff5GmXWRcEFWFmhaUdGuWyJO53EvcZkrnfSdxnqNz9VtOQiEjCKQhERBIuaUFwf9wFxCSJ+53EfYZk7ncS9xkqcb8T1UcgIiL/K2lHBCIiUoKCQEQk4RITBOWZLS3bmVlzM5uYMuPbRdHy7c3sZTP7PPp3u7hrTQczyzOzD8xsXPS4pZm9G33m/4rGvMoZZtbAzJ4ys0/N7BMzOzAJn7WZ/TH6/z3TzEaZWa1c/KzN7GEzW2JmM1OWbfLzteCOaP9nmNl+W/JeiQiClNnSugHtgL5m1i7eqtJiHXCpu7cDOgIXRPt5OfCqu7cBXo0e56KLCONaFbsRuM3dWwPLgbNiqSp9bgdedPfdgX0I+57Tn7WZNQUuBArcfS8gjzCgZS5+1iOAknO0lPb5diOM3NwGGAjcsyVvlIggoHyzpWU9d1/s7tOi+z8QvhiaEvb10WizR4HjYykwjcysGXAc8GD02IDOwFPRJjm132ZWHzgUeAjA3X9y9+9IwGdNmMektpnlA3WAxeTgZ+3ubwLLSiwu7fPtBTzmwRSggZntWN73SkoQlGe2tJxiZi2AfYF3gSbuvjha9TXQJK660mg4cBmwIXrcEPguGgUXcu8zbwkUAY9EzWEPmlldcvyzdvevgGHAl4QA+B54n9z+rFOV9vlW6DsuKUGQKGa2DfA0cLG7r0hd5+F84Zw6Z9jMugNL3P39uGupQvnAfsA97r4vsIoSzUA5+llvR/j12xLYCajL/zafJEJlfr5JCYLyzJaWE8ysOiEEnnD3Z6LF3xQfJkb/LomrvjQ5GOhpZvMIzX6dCe3nDaLmA8i9z3whsNDd340eP0UIhlz/rI8EvnD3Inf/GXiG8Pnn8medqrTPt0LfcUkJgvLMlpb1onbxh4BP3P3WlFVjgQHR/QHAmKquLZ3c/Qp3b+buLQif7Wvu3o8w2VHvaLOc2m93/xpYYGZto0VdgI/J8c+a0CTU0czqRP/fi/c7Zz/rEkr7fMcCp0VnD3UEvk9pQto8d0/EDTiWMCfyHODKuOtJ0z52IhwqzgCmR7djCe3lrwKfA68A28ddaxr/BocD46L7rYCpwGzg30DNuOur5H1tDxRGn/dzwHZJ+KyB64BPgZnAP4GaufhZA6MI/SA/E44Azyrt8wWMcGbkHOBDwllV5X4vDTEhIpJwSWkaEhGRUigIREQSTkEgIpJwCgIRkYRTEIiIJJyCQDKWmbmZ3ZLy+E9mdm0lvfYIM+u9+S0r/D4nRSODTiyxvIWZrTaz6Sm30yrxfQ8vHoVVZHPyN7+JSGzWAiea2d/d/du4iylmZvm+cVybzTkLONvd39rEujnu3r7yKhPZOjoikEy2jjAv6x9Lrij5i97MVkb/Hm5mb5jZGDOba2Y3mFk/M5tqZh+a2a4pL3OkmRWa2WfReEXFcxrcbGbvReO6n5PyupPMbCzhStaS9fSNXn+mmd0YLbuacJHfQ2Z2c3l32sxWmtlt0Zj7r5pZ42h5ezObEtX1bMpY9K3N7BUz+6+ZTUvZx21s43wFT0RX4hL9TT6OXmdYeeuSHBb31XO66VbaDVgJ1APmAfWBPwHXRutGAL1Tt43+PRz4DtiRcMXpV8B10bqLgOEpz3+R8GOoDeHKzVqEsdyvirapSbhyt2X0uquAlpuocyfC0AeNCUfZrwHHR+teZxNXeQItgNVsvAJ8OnBItM6BftH9q4E7o/szgMOi+0NT9uVd4ITofi3C0MyHE0bmbBbt42RCKDUEZrFxvvIGcX/OusV/0xGBZDQPo6c+RpiMpLze8zA3w1rCJfcvRcs/JHwBFxvt7hvc/XNgLrA7cDRhzJbphC/YhoSgAJjq7l9s4v32B173MBDaOuAJwlwBmzPH3dun3CZFyzcA/4ruPw50iuYfaODub0TLHwUONbNtgabu/iyAu69x9x9T6l3o7hsIQdOCEA5rCEcpJwLF20qCKQgkGwwntLXXTVm2juj/r5lVA1KnJlybcn9DyuMN/LJfrOT4Kk4Ys2VQypdzS3cvDpJVFdmJCtjacWBS/w7rgeK+jQ6E0Uq7E46KJOEUBJLx3H0ZMJpfTj84D/hNdL8nUH0rXvokM6sWtam3IjSZTADOi4bzxsx2iyZ8KctU4DAzaxRNi9oXeGMzzylLNTaOpPk74C13/x5YbmaHRMv7A294mIluoZkdH9Vb08zqlPbC0VwV9d39eULfyz4VqFNyhM4akmxxC/CHlMcPAGPM7L+EX7Vb82v9S8KXeD3gXHdfY2YPEppQpkWdq0VsZtpDd19sZpcThkI2YLy7l2cY5F2jJqhiD7v7HYR96WBmVxHGm+8TrR8A3Bt90c8FzoiW9wfuM7OhhJEqTyrjPbcl/N1qRbVeUo46Jcdp9FGRDGNmK919m7jrkORQ05CISMLpiEBEJOF0RCAiknAKAhGRhFMQiIgknIJARCThFAQiIgn3/wFJEdeDvIGtegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(losses)), losses, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbecd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = prot_embeddings.detach().cpu().numpy()\n",
    "drugs = embeddings1.detach().cpu().numpy()\n",
    "diseases = embeddings2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d83adc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings = dict()\n",
    "save_embeddings[\"proteins\"] = proteins\n",
    "save_embeddings[\"drugs\"] = drugs\n",
    "save_embeddings[\"diseases\"] = diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55ed5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./embeddings.pkl', 'wb') as f:   # the whole dataset\n",
    "    pickle.dump(save_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d15c7568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1852033 ,  1.2074946 , -0.68478924, -0.38683727,  0.7466029 ,\n",
       "        0.7582197 ,  0.5772464 ,  0.01250559, -0.7902996 , -0.5219326 ,\n",
       "       -1.6259668 , -1.2220792 , -1.6374283 , -0.19371529,  0.20221747,\n",
       "       -0.0061234 ], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseases[1446]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433072e",
   "metadata": {},
   "source": [
    "## Getting top hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd786576",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./final_data.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "data = Data.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e92e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = prot_embeddings.detach().cpu()\n",
    "drugs = embeddings1.detach().cpu()\n",
    "diseases = embeddings2.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bd0a4158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 1445, 1447, 1447],\n",
       "        [  74,  102,  113,  ..., 6107,  450,  859]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dd_edge_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1ced6f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7098, 0.9087, 0.8555,  ..., 0.8953, 0.7427, 0.8703])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.decoder(drugs, diseases, data[\"dd_edge_index\"]).detach()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eb488ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1446, 1446, 1446,  ..., 1446, 1446, 1446],\n",
       "        [   0,    1,    2,  ..., 6155, 6156, 6157]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_edges = torch.zeros((2, data[\"n_drug\"]), dtype=int)\n",
    "for i in range(data[\"n_drug\"]):\n",
    "    covid_edges[0][i] = 1446 # corresponds to sars-cov-2\n",
    "    covid_edges[1][i] = int(i)\n",
    "covid_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a0fbd875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1817e-05, 1.0638e-07, 1.0981e-05,  ..., 7.9057e-05, 1.1650e-05,\n",
       "        8.4606e-04])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.decoder(drugs, diseases, covid_edges).detach()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f89969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dict()\n",
    "for i in range(data[\"n_drug\"]): \n",
    "    pred[i] = output[i]\n",
    "sorted_pred = dict(sorted(pred.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8c622344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2899, 102, 682, 5184, 6107]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_in_order = []\n",
    "for key in sorted_pred:\n",
    "    indices_in_order.append(key)\n",
    "    \n",
    "indices_in_order[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "006a2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2899, 102, 682, 5184, 6107, 865, 137, 907, 3462, 2581, 1809, 462, 324, 113, 1229, 1228, 442, 105, 488, 686, 5215, 293, 122, 1698, 2496, 2634, 148, 274, 1209, 529, 864, 175, 1102, 393, 574, 942, 144, 970, 149, 162, 998, 6099, 703, 358, 386, 204, 280, 3185, 1144, 5871, 3271, 580, 727, 872, 432, 285, 5238, 3317, 713, 3693, 98, 739, 2165, 949, 427, 202, 3071, 3704, 5505, 938, 908, 834, 481, 229, 414, 94, 380, 1866, 1373, 1495, 1889, 2553, 2762, 508, 524, 169, 609, 676, 785, 160, 89, 734, 3728, 3729, 449, 1320, 1361, 1399, 2571, 2744, 948, 3095, 1987, 2790, 506, 698, 1911, 6096, 120, 981, 977, 373, 509, 659, 5258, 119, 3319, 2988, 1022, 5300, 1064, 74, 77, 547, 353, 2599, 248, 130, 1314, 584, 1180, 861, 808, 640, 1539, 722, 1309, 1327, 91, 5776, 5815, 6020, 1086, 236, 646, 781, 694, 294, 825, 181, 2780, 1326, 6040, 6064, 2875, 141, 3000, 1112, 1321, 5580, 480, 891, 492, 884, 347, 810, 3361, 3479, 673, 793, 435, 2924, 3196, 3687, 740, 5730, 452, 599, 918, 649, 614, 930, 5360, 5182, 538, 566, 934, 374, 824, 267, 628, 413, 852, 329, 95, 6072, 749, 850, 317, 5385, 5758, 724, 474, 941, 75, 111, 943, 487, 332, 1201, 720, 366, 392, 985, 1279, 1322, 5543, 5260, 402, 2960, 3726, 1038, 1252, 5719, 1220, 518, 813, 389, 3599, 166, 1011, 1206, 3652, 5985, 639, 3735, 528, 621, 290, 687, 978, 946, 626, 5179, 871, 5157, 1877, 99, 428, 1304, 712, 2514, 804, 854, 1019, 1294, 1936, 2315, 2367, 2441, 2648, 4424, 4600, 4797, 4798, 5071, 6011, 3348, 657, 906, 5326, 1641, 2789, 352, 833, 1131, 475, 1125, 925, 207, 1204, 1003, 3341, 1328, 265, 1109, 1391, 2357, 249, 5924, 1303, 1123, 1203, 1002, 464, 187, 271, 5371, 939, 4765, 4766, 4767, 5491, 537, 1194, 2307, 3764, 1483, 888, 88, 451, 3725, 422, 658, 960, 472, 1192, 250, 638, 1792, 565, 500, 887, 1312, 730, 1197, 2977, 1669, 656, 1084, 903, 3349, 5828, 777, 606, 553, 3516, 136, 959, 633, 260, 769, 1132, 147, 3620, 873, 748, 444, 3338, 245, 963, 1175, 5461, 623, 196, 600, 695, 705, 855, 3145, 1054, 5318, 795, 2851, 4000, 5942, 843, 618, 1521, 2127, 2638, 369, 225, 1119, 642, 962, 5632, 411, 967, 3747, 180, 425, 433, 1074, 624, 273, 2837, 174, 571, 707, 1105, 307, 797, 980, 3668, 3707, 5595, 5661, 1313, 1149, 193, 711, 434, 897, 679, 3711, 1049, 700, 1134, 6038, 295, 689, 6053, 531, 5472, 1821, 2592, 875, 550, 3744, 5254, 5380, 1072, 1117, 221, 612, 3593, 5760, 403, 641, 1015, 1336, 573, 820, 5563, 990, 177, 242, 1030, 1959, 2248, 1232, 596, 966, 320, 479, 1223, 601, 909, 1256, 5148, 239, 671, 2700, 2963, 342, 416, 456, 465, 895, 1127, 1097, 2954, 495, 859, 1028, 5227, 3724, 3207, 5376, 5377, 5822, 1121, 514, 674, 199, 751, 670, 237, 1069, 1018, 115, 387, 669, 735, 844, 1196, 1198, 1316, 1317, 2164, 2882, 2940, 3705, 4235, 4309, 4642, 5103, 5104, 5323, 5328, 5356, 5469, 5470, 5575, 5895, 5952, 5981, 564, 3180, 223, 410, 127, 116, 157, 215, 226, 289, 595, 763, 812, 1234, 881, 851, 645, 1335, 1076, 5234, 1032, 4888, 5928, 3395, 965, 155, 201, 1666, 551, 761, 771, 815, 1276, 1295, 1311, 3544, 3588, 5384, 1222, 3734, 1048, 5500, 5553, 5442, 662, 995, 5414, 153, 922, 1040, 5349, 1386, 2642, 302, 335, 653, 708, 3363, 5908, 3549, 1130, 5205, 519, 2206, 395, 297, 1655, 2304, 1115, 753, 821, 5417, 212, 1128, 617, 5185, 1379, 1239, 287, 733, 370, 203, 243, 932, 603, 5697, 6037, 3733, 816, 106, 901, 234, 807, 1791, 2951, 3481, 5149, 5259, 5893, 5916, 6012, 1120, 497, 1601, 2215, 2723, 3936, 4259, 4425, 4589, 4590, 4591, 5042, 544, 3709, 5918, 2729, 5438, 3698, 152, 2891, 868, 220, 723, 1021, 691, 5556, 774, 378, 936, 1251, 5752, 530, 5937, 721, 1435, 1065, 466, 404, 2443, 539, 396, 179, 697, 3591, 5315, 5454, 999, 578, 304, 1334, 1246, 732, 717, 559, 5782, 1199, 572, 561, 316, 184, 282, 5626, 911, 501, 867, 1089, 1572, 799, 5422, 2433, 927, 2958, 627, 876, 742, 210, 944, 849, 1042, 408, 3772, 5789, 2956, 654, 3714, 186, 953, 5511, 1139, 454, 2322, 1527, 1728, 1788, 1879, 2624, 2814, 2847, 701, 1559, 1941, 916, 268, 827, 318, 958, 1258, 823, 333, 1274, 3335, 3016, 5367, 3205, 1124, 5228, 185, 2930, 496, 805, 644, 1073, 453, 1324, 5826, 762, 1219, 1051, 5244, 629, 5382, 183, 527, 1181, 3487, 3702, 5761, 405, 533, 1205, 1080, 377, 3706, 567, 899, 458, 197, 3122, 3703, 5576, 5967, 337, 5935, 680, 230, 399, 933, 1083, 1854, 1916, 4297, 4614, 4953, 306, 400, 1066, 305, 313, 200, 493, 756, 3267, 5840, 920, 631, 350, 5562, 5613, 5833, 23, 668, 2993, 3279, 3527, 5366, 5722, 6023, 6024, 6031, 6032, 6033, 6034, 685, 976, 1114, 4983, 1332, 198, 1179, 5243, 173, 1050, 5785, 5724, 3056, 5186, 576, 5547, 1366, 264, 788, 5431, 773, 522, 159, 608, 482, 1237, 5307, 164, 1183, 3721, 5471, 5887, 869, 3019, 325, 643, 447, 429, 582, 778, 5020, 3577, 526, 1349, 622, 801, 383, 570, 1278, 1253, 5249, 1041, 5177, 1174, 146, 523, 355, 1147, 255, 6117, 6009, 728, 752, 5152, 448, 853, 1090, 1100, 602, 1154, 794, 5660, 259, 1082, 1794, 1300, 5373, 1034, 375, 205, 284, 1257, 1333, 3075, 5270, 5665, 5751, 505, 715, 301, 1191, 782, 5408, 3615, 515, 356, 800, 478, 1249, 1108, 877, 1660, 491, 151, 1263, 1259, 5478, 443, 1211, 296, 238, 5223, 630, 1494, 1979, 2284, 2519, 2746, 2833, 6105, 5369, 1036, 359, 1217, 270, 2710, 1060, 1061, 5378, 328, 132, 5736, 893, 784, 477, 945, 5176, 1095, 277, 1075, 3017, 660, 857, 919, 1025, 1244, 1955, 331, 170, 690, 2306, 636, 1027, 5213, 951, 759, 315, 1133, 993, 6104, 1403, 1748, 2250, 2617, 484, 1079, 661, 379, 6019, 915, 362, 1630, 1824, 1840, 1977, 2088, 2283, 2564, 2701, 2791, 213, 3592, 577, 1352, 2767, 3469, 3299, 303, 2029, 3663, 835, 279, 431, 1165, 1202, 666, 798, 779, 188, 885, 209, 541, 637, 996, 870, 3710, 2092, 2301, 2349, 2695, 2722, 856, 1282, 469, 1107, 1111, 5271, 568, 2804, 665, 863, 485, 1886, 1340, 1347, 3513, 154, 1158, 246, 5294, 5607, 2294, 276, 2286, 6079, 892, 1289, 971, 1088, 8, 15, 30, 52, 58, 59, 3297, 1168, 964, 3716, 5851, 1189, 1013, 548, 489, 214, 5723, 540, 176, 1009, 441, 1221, 956, 437, 5763, 262, 1135, 5695, 786, 5298, 319, 766, 1046, 5800, 1081, 688, 283, 696, 1024, 1275, 5882, 1005, 1017, 2880, 4561, 446, 3507, 796, 842, 620, 5379, 450, 1607, 5000, 323, 412, 1512, 837, 768, 216, 272, 417, 1215, 1216, 1291, 880, 536, 1023, 1138, 5381, 455, 829, 1271, 6120, 486, 1236, 426, 611, 5955, 1070, 743, 1270, 5374, 3088, 991, 1098, 3428, 1101, 5348, 1453, 1556, 1608, 1700, 1832, 1990, 2018, 2066, 2182, 2198, 2488, 2490, 2520, 2548, 2798, 3913, 5874, 961, 3770, 1242, 254, 3701, 545, 1362, 1867, 2437, 3842, 1156, 3672, 5206, 6025, 6026, 6027, 6028, 6030, 1140, 3562, 1155, 973, 3081, 463, 1214, 87, 2948, 430, 1240, 1250, 1882, 972, 18, 832, 3379, 1137, 923, 879, 1213, 5614, 591, 5667, 298, 2194, 2449, 2973, 3202, 3621, 2858, 789, 5560, 156, 5542, 2229, 2319, 3691, 1420, 1285, 3775, 5425, 3084, 1272, 552, 2980, 684, 1045, 2505, 3466, 563, 360, 836, 1746, 2141, 348, 586, 1129, 883, 1004, 406, 1511, 1514, 2336, 2454, 2607, 1687, 1805, 1830, 2103, 2353, 2587, 2704, 397, 1006, 1177, 2805, 6086, 1031, 1044, 3632, 118, 3603, 747, 585, 1364, 5829, 828, 385, 588, 1063, 898, 3011, 616, 904, 278, 594, 905, 678, 490, 1238, 445, 291, 755, 423, 1394, 1396, 1509, 1690, 1978, 2344, 2543, 2578, 4997, 172, 693, 1033, 1153, 1231, 3757, 5699, 5863, 3720, 3731, 984, 532, 2946, 261, 997, 3351, 3034, 3777, 401, 165, 1265, 605, 862, 2947, 775, 702, 1297, 5743, 5744, 5966, 266, 651, 3294, 1281, 390, 467, 1067, 3398, 6149, 5707, 1874, 1993, 2128, 2658, 2756, 3215, 3955, 882, 992, 886, 5158, 1926, 1957, 2616, 3097, 3320, 4137, 4168, 4177, 4973, 5526, 845, 947, 590, 2870, 2900, 1273, 758, 921, 300, 5247, 741, 438, 6095, 6152, 235, 1167, 349, 1931, 952, 507, 1178, 5492, 792, 1392, 1449, 1735, 1800, 1860, 1872, 2236, 2556, 2689, 5616, 5246, 583, 839, 5711, 1960, 3649, 5189, 253, 224, 222, 878, 1724, 2228, 2665, 2802, 2853, 2920, 1008, 286, 192, 354, 5, 84, 765, 3352, 562, 341, 983, 950, 2942, 1193, 3634, 3522, 910, 288, 767, 1743, 3679, 309, 736, 817, 1224, 3333, 3389, 3774, 4329, 5615, 5753, 510, 650, 1078, 1548, 5867, 3111, 5167, 4493, 543, 2434, 3126, 3221, 3283, 4347, 4969, 4970, 5102, 440, 926, 555, 357, 1286, 161, 1241, 1104, 1093, 5982, 420, 704, 6081, 5199, 171, 498, 1587, 1772, 1845, 1946, 2038, 2148, 2217, 2316, 2635, 2737, 3098, 4446, 4497, 4499, 4500, 473, 1094, 372, 593, 940, 3004, 1318, 725, 191, 683, 517, 1323, 194, 840, 363, 384, 818, 894, 988, 1341, 1344, 2957, 3005, 3232, 3546, 3745, 5150, 5151, 5153, 5252, 5495, 6137, 598, 96, 211, 2996, 5516, 1757, 330, 3680, 338, 1118, 168, 3484, 218, 521, 1907, 3264, 625, 1020, 334, 525, 251, 502, 714, 592, 3321, 607, 5154, 1266, 549, 4113, 5645, 914, 826, 344, 3058, 3350, 3411, 3441, 3594, 5292, 632, 1056, 415, 143, 5629, 1268, 3382, 314, 1487, 419, 6157, 575, 436, 1000, 1306, 3722, 3730, 3776, 5255, 5671, 5676, 5748, 5820, 5896, 5903, 5906, 5923, 5927, 3536, 738, 557, 476, 5968, 5969, 398, 24, 546, 263, 2016, 2857, 4906, 5849, 376, 1346, 757, 346, 5773, 5533, 1047, 847, 1329, 131, 955, 1136, 5439, 3692, 5330, 5970, 311, 1457, 1555, 1637, 1923, 2365, 2410, 2411, 4633, 4635, 4636, 5780, 424, 989, 560, 322, 589, 1091, 2962, 5197, 1254, 3235, 1353, 718, 979, 5690, 5319, 3521, 987, 975, 2337, 299, 913, 924, 1255, 2151, 3623, 407, 409, 2687, 2944, 5288, 1348, 1103, 3468, 3779, 6, 12, 25, 647, 1141, 308, 2941, 3520, 163, 1284, 3038, 5170, 556, 802, 5728, 1910, 1062, 3686, 783, 780, 1096, 244, 2966, 569, 5721, 1302, 3708, 5885, 368, 5627, 5180, 2473, 655, 1338, 675, 841, 228, 3712, 2754, 5522, 2806, 371, 364, 2950, 2253, 1159, 1461, 1516, 1718, 1826, 1891, 1935, 2116, 2130, 2193, 2258, 2292, 2397, 2418, 2431, 2777, 5040, 5074, 764, 848, 3696, 6135, 1200, 3689, 2381, 3563, 67, 1770, 2485, 2938, 3845, 4193, 6113, 5165, 4423, 1697, 2009, 2142, 2345, 2352, 3888, 4232, 4448, 4491, 4575, 4669, 4968, 2102, 2269, 2442, 2660, 4361, 4467, 4473, 4511, 4580, 4743, 4744, 5016, 5059, 5069, 5512, 232, 5289, 5290, 5418, 182, 1330, 1367, 1388, 1518, 4221, 4223, 4416, 4474, 4574, 4735, 4910, 5025, 5026, 5088, 5089, 1789, 2003, 2097, 2271, 2428, 2588, 2667, 3901, 874, 900, 1243, 1245, 1260, 1331, 3769, 5386, 5388, 5389, 5517, 5520, 5552, 5567, 5901, 367, 195, 421, 439, 613, 2808, 3037, 2388, 3026, 292, 1071, 1358, 3055, 269, 85, 579, 597, 3336, 3627, 3700, 3760, 3763, 3781, 5435, 1549, 1692, 1784, 2033, 2243, 2509, 3898, 4870, 6094, 1571, 5390, 5824, 5843, 5603, 468, 2546, 340, 5446, 3412, 3504, 5304, 5718, 3524, 4, 5842, 138, 5804, 3029, 240, 3239, 5155, 5156, 760, 1503, 2100, 4276, 4277, 4278, 4846, 937, 3477, 610, 746, 770, 866, 1052, 1087, 1150, 1188, 1190, 1226, 1283, 1421, 2241, 2293, 2566, 2953, 3002, 3033, 3300, 3405, 3478, 3547, 3611, 3690, 3736, 3743, 4988, 5231, 5233, 5256, 5261, 5262, 5264, 5266, 5274, 5333, 5403, 5409, 5447, 5448, 5476, 5578, 5581, 5582, 5586, 5591, 5592, 5593, 5594, 5597, 5600, 5602, 5635, 5663, 5664, 5666, 5674, 5677, 5680, 5698, 5706, 5726, 5727, 5737, 5755, 5774, 5788, 5790, 5794, 5805, 5834, 5836, 5853, 5879, 5883, 5884, 5886, 5889, 5890, 5892, 5894, 5898, 5899, 5900, 5905, 5910, 5914, 5917, 5919, 5925, 5930, 5934, 5936, 5973, 5984, 6008, 6075, 6082, 6084, 1665, 2276, 2295, 2664, 2813, 3130, 3624, 4257, 4340, 4341, 4400, 4628, 4629, 4630, 4631, 4653, 4655, 4776, 4778, 4833, 604, 4948, 2952, 5214, 667, 6065, 6066, 6067, 6068, 6069, 6070, 6071, 2898, 9, 13, 4392, 5224, 5337, 744, 1717, 5412, 5334, 860, 2247, 5341, 1374, 1010, 1110, 3739, 5621, 3012, 247, 1145, 2384, 2611, 460, 982, 1058, 1085, 1208, 1230, 1269, 5990, 6045, 6046, 6054, 6055, 615, 1106, 3092, 3768, 3007, 459, 158, 3070, 5221, 1267, 5554, 5183, 5585, 634, 5276, 1235, 3365, 5766, 1126, 1160, 3119, 3241, 3268, 3322, 4364, 5508, 5747, 5865, 391, 1422, 1625, 2050, 2493, 2750, 2886, 2887, 2888, 4514, 4881, 4883, 4886, 4894, 4895, 4900, 4902, 4967, 5073, 1460, 2778, 345, 381, 729, 928, 3762, 5314, 5195, 1633, 1813, 2883, 3645, 5277, 838, 652, 5636, 1315, 70, 986, 5457, 336, 3715, 1037, 3756, 189, 1681, 1934, 2045, 2233, 2402, 2518, 2712, 3836, 3886, 3960, 4006, 4057, 4726, 1359, 1814, 1983, 2463, 4229, 4449, 5340, 3639, 2965, 461, 6078, 321, 2547, 3172, 4395, 4588, 5413, 5943, 1369, 1389, 1404, 1406, 1409, 1425, 1456, 1475, 1499, 1553, 1565, 1578, 1580, 1597, 1670, 1679, 1714, 1719, 1753, 1765, 1870, 1908, 1937, 1973, 2024, 2039, 2073, 2122, 2143, 2158, 2162, 2201, 2219, 2245, 2256, 2309, 2329, 2540, 2585, 2595, 2632, 2644, 2646, 2656, 2672, 2675, 2688, 2714, 2730, 2733, 2738, 2741, 2757, 2801, 2926, 2927, 2928, 2929, 3792, 3848, 3851, 4100, 4212, 4291, 4637, 4787, 4939, 5122, 5427, 803, 3506, 1818, 1835, 3375, 5030, 5058, 5630, 5551, 822, 1767, 3832, 4916, 4928, 1116, 5477, 1444, 1526, 1951, 2136, 2467, 2731, 1319, 1092, 45, 55, 3043, 3179, 3364, 3396, 3431, 3437, 3604, 3628, 3684, 5212, 470, 3751, 5346, 1441, 1473, 1658, 2300, 2317, 2376, 4585, 5131, 3551, 516, 2190, 2273, 2462, 3115, 3771, 5391, 5590, 5868, 6022, 6112, 1368, 1561, 1709, 1939, 2013, 2157, 2191, 2416, 2534, 2597, 2610, 2934, 4266, 4362, 4863, 4864, 4865, 2482, 1858, 233, 969, 1864, 2036, 2138, 2254, 2560, 2678, 3852, 4200, 4286, 4905, 5121, 5527, 5424, 2043, 2342, 2455, 2483, 2609, 2836, 2917, 2918, 2922, 2413, 3605, 503, 2531, 4616, 5235, 5437, 2974, 69, 5561, 5440, 1016, 1059, 3552, 5375, 2104, 2196, 4784, 2495, 2732, 5555, 716, 3613, 3074, 3485, 1488, 1798, 2464, 3804, 3197, 3245, 5710, 6139, 2964, 968, 2961, 619, 2356, 101, 5998, 737, 1055, 1248, 1288, 1606, 1781, 3490, 3538, 3660, 3746, 3748, 4264, 5263, 5587, 5589, 5598, 5599, 5673, 5694, 5775, 5835, 5878, 5881, 5897, 5907, 5909, 5913, 5915, 5926, 5932, 5933, 6007, 6010, 3309, 1354, 2580, 3370, 19, 51, 5217, 5265, 5529, 5777, 5891, 2683, 3417, 312, 394, 2949, 1968, 1371, 2570, 1464, 4242, 4451, 4498, 4566, 4571, 4852, 5067, 3658, 310, 1958, 3184, 5245, 5784, 5796, 5971, 3480, 5173, 1624, 1965, 2895, 635, 3024, 2562, 3156, 1650, 1652, 1732, 1823, 1932, 1963, 2086, 2305, 2338, 2469, 2653, 2901, 2902, 2904, 3496, 1501, 974, 2261, 2652, 2932, 3213, 3500, 1186, 5509, 1299, 117, 2028, 1603, 4248, 4249, 4399, 4708, 4841, 4974, 5060, 494, 1525, 1736, 1773, 1812, 1887, 2056, 2074, 2272, 2399, 2426, 2561, 2614, 3805, 3806, 3976, 4013, 4019, 4383, 4384, 4706, 5092, 2427, 6004, 6005, 6151, 1035, 787, 542, 554, 1142, 1280, 1351, 3509, 5411, 5394, 3669, 5395, 3316, 5434, 831, 5608, 1413, 1458, 1628, 1742, 1884, 2120, 2156, 2371, 2903, 3234, 3827, 3840, 3862, 3951, 4059, 4075, 4110, 4147, 4434, 4435, 4436, 4477, 4492, 4617, 4618, 4727, 4728, 4729, 4730, 4731, 4800, 4801, 4802, 5642, 5222, 1617, 1675, 1676, 2001, 2334, 4370, 4376, 4379, 4381, 1262, 1689, 1857, 1981, 2078, 2234, 2586, 3392, 4165, 4169, 4178, 4179, 4218, 4472, 5061, 3512, 5912, 1547, 2369, 2630, 3566, 4837, 4838, 4839, 4840, 5803, 1099, 1448, 1462, 1710, 1756, 1797, 1839, 1894, 1895, 1954, 2012, 2068, 2106, 2147, 2161, 2176, 2211, 2225, 2230, 2275, 2359, 2446, 2544, 2554, 2558, 2623, 2669, 2792, 2843, 2844, 2845, 2846, 3900, 3966, 4506, 4507, 4516, 4608, 4762, 4871, 4987, 4989, 2129, 5324, 5280, 125, 2914, 2919, 663, 719, 5507, 4412, 2325, 710, 1007, 929, 2112, 2137, 2155, 2174, 2364, 2451, 3284, 2795, 1534, 3302, 5999, 5945, 5946, 3442, 142, 3460, 5657, 5685, 5659, 5548, 2711, 5343, 1834, 890, 6136, 1184, 256, 1068, 1212, 3250, 3498, 677, 3001, 3094, 5651, 365, 3542, 1964, 2425, 4556, 3287, 5044, 3118, 3342, 1343, 1476, 1480, 1583, 1636, 1682, 1711, 1720, 1758, 1804, 1838, 1861, 1984, 2011, 2015, 2041, 2184, 2213, 2216, 2282, 2321, 2362, 2403, 2435, 2539, 2582, 2602, 2620, 2639, 2668, 2724, 2727, 2779, 2826, 2856, 2859, 3829, 3891, 3897, 3934, 3957, 3965, 4049, 4061, 4083, 4092, 4228, 4292, 4298, 4301, 4318, 4320, 4327, 4359, 4367, 4371, 4377, 4380, 4427, 4428, 4429, 4460, 4475, 4476, 4479, 4483, 4504, 4505, 4570, 4599, 4634, 4638, 4639, 4640, 4670, 4671, 4721, 4737, 4738, 4739, 4740, 4741, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4831, 4867, 4949, 4991, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012, 5065, 5076, 5080, 5125, 38, 1685, 2057, 2308, 5415, 5237, 2943, 5450, 5451, 1623, 1651, 1707, 1739, 1873, 1944, 2031, 2175, 2208, 2212, 2550, 2590, 2796, 2829, 2830, 2831, 2832, 2978, 2982, 3638, 4336, 4440, 4480, 4540, 4774, 4898, 5054, 5268, 5902, 6153, 5211, 1290, 1122, 5701, 1157, 388, 5459, 1225, 2693, 2699, 513, 5648, 5351, 5361, 5499, 252, 3326, 664, 3048, 3310, 5628, 1820, 2368, 1397, 1678, 2108, 2118, 1816, 1393, 1604, 1659, 1942, 1970, 2042, 2063, 2567, 2589, 2676, 2743, 5535, 219, 90, 3374, 2420, 2447, 2528, 4311, 4354, 4355, 4533, 4563, 4794, 5051, 5117, 5118, 3493, 5811, 2251, 3108, 4859, 1586, 1643, 2478, 2673, 2864, 4305, 4306, 4711, 4782, 4971, 4995, 5852, 190, 931, 681, 2533, 2685, 3444, 3964, 4672, 4673, 4675, 4796, 4825, 4829, 4830, 4834, 1410, 2121, 2709, 3224, 3347, 3454, 3467, 1780, 2006, 1463, 3631, 3665, 2008, 1176, 206, 1771, 1661, 1768, 1906, 2173, 2267, 3292, 3941, 4155, 3381, 731, 5187, 814, 1850, 6074, 2314, 1172, 3688, 2461, 5407, 1385, 6125, 3376, 6036, 3510, 1415, 2358, 2884, 4040, 4314, 4664, 4773, 4816, 5095, 5096, 5097, 5098, 1479, 1535, 2163, 2360, 2809, 2810, 2992, 3066, 3440, 3471, 3823, 3866, 3906, 3907, 3926, 3931, 3967, 3972, 3981, 3989, 4025, 4042, 4063, 4069, 4109, 4138, 4183, 4203, 4240, 4274, 4285, 4415, 4495, 4524, 4544, 4666, 4681, 4687, 4771, 4913, 4944, 4952, 4990, 5003, 5034, 5075, 5110, 5656, 3014, 1627, 2498, 2890, 3889, 4288, 3695, 241, 1763, 3630, 2769, 811, 511, 5387, 1424, 3797, 3800, 3803, 3807, 3986, 3988, 3992, 4021, 4836, 3358, 5474, 5272, 1387, 2255, 2559, 5273, 2004, 2313, 2323, 4408, 4530, 846, 339, 3078, 3574, 3595, 3494, 6127, 6144, 772, 1057, 1592, 1749, 1819, 1829, 1994, 2062, 2099, 2210, 2378, 2529, 3572, 4029, 4030, 4031, 4033, 4820, 4931, 4954, 5064, 1447, 1545, 1574, 2386, 2636, 4660, 4661, 2657, 2873, 3308, 3390, 3854, 3956, 4004, 4055, 4081, 4082, 4161, 4304, 4419, 4456, 4536, 4736, 4862, 4945, 5021, 5120, 5681, 5808, 6013, 2303, 1497, 2834, 3383, 5482, 1896, 957, 3039, 672, 806, 5596, 1478, 1900, 4569, 4878, 4879, 4880, 5771, 1376, 1471, 1484, 1489, 1505, 1701, 1752, 1919, 1988, 2072, 2089, 2094, 2146, 2168, 2181, 2183, 2296, 2326, 2348, 2391, 2444, 2572, 2771, 2896, 3474, 3825, 4621, 4688, 4689, 4690, 4792, 4961, 5024, 2119, 3540, 3089, 3438, 3476, 3325, 5869, 3261, 1619, 2059, 2773, 4813, 5420, 5466, 1195, 3214, 3553, 5745, 3031, 889, 5370, 3025, 5929, 2242, 2871, 1383, 4056, 4145, 3499, 4007, 3402, 1730, 4261, 5124, 2470, 5647, 3222, 3794, 1593, 2200, 2486, 4273, 4686, 5609, 6001, 3209, 2945, 5611, 5530, 1598, 2139, 2382, 2414, 2474, 3875, 4252, 4611, 4612, 4613, 4654, 5053, 5062, 5063, 5870, 1493, 1500, 1616, 1842, 2579, 3892, 4014, 4106, 4269, 896, 5285, 2643, 1152, 4595, 2227, 1043, 5302, 809, 2423, 1143, 326, 3, 258, 1482, 6035, 3525, 327, 3583, 3657, 3622, 5479, 512, 5358, 3082, 3554, 2481, 1113, 3610, 5579, 6155, 351, 3483, 3732, 754, 257, 1437, 2440, 3749, 5731, 3424, 2154, 1596, 1161, 3401, 3675, 4914, 4915, 4917, 4918, 4920, 4921, 5994, 5995, 5316, 2058, 3313, 3266, 5372, 558, 3057, 2598, 3120, 3146, 3275, 1667, 1705, 2494, 3042, 3616, 5798, 5809, 1492, 1261, 2318, 5920, 917, 5123, 1264, 2976, 5275, 5791, 5799, 3656, 5160, 3578, 2499, 2647, 1247, 2048, 2385, 3340, 587, 1677, 750, 4332, 1591, 2002, 2393, 1029, 3076, 3318, 3307, 1589, 3600, 5396, 1761, 208, 2975, 3738, 3101, 5817, 5441, 581, 5085, 4330, 3614, 2986, 2649, 4190, 4790, 4814, 5111, 2852, 1001, 3212, 5634, 4450, 178, 1287, 1298, 1307, 2000, 2881, 3188, 3472, 3816, 3948, 4151, 4243, 4244, 4245, 4246, 4265, 4452, 4489, 4674, 4715, 4716, 4717, 4960, 5584, 5588, 5965, 6085, 6100, 1450, 535, 5549, 1776, 2383, 2583, 2202, 819, 1668, 5267, 5765, 2820, 3517, 5847, 50, 1433, 2091, 2448, 1915, 4811, 1684, 3003, 1560, 2984, 281, 5633, 3079, 3404, 3453, 3565, 4043, 4280, 5754, 2972, 3069, 3161, 3514, 5126, 1301, 1599, 3244, 3713, 2523, 2997, 3200, 1986, 5974, 5078, 5841, 3838, 3890, 4287, 41, 42, 1185, 1187, 5939, 1646, 2860, 4417, 3589, 5293, 2220, 3433, 16, 80, 5209, 5738, 1400, 3113, 3386, 5959, 5618, 3125, 3128, 5352, 1726, 3452, 3858, 3929, 3987, 4003, 4058, 4079, 4114, 4146, 4149, 4162, 4195, 4196, 4241, 4310, 4323, 4345, 4462, 4463, 4464, 4465, 4466, 4559, 4643, 4644, 5114, 5759, 5496, 5429, 5383, 5786, 3175, 5684, 4080, 4116, 4818, 3683, 2931, 4439, 1342, 3051, 3230, 3331, 3582, 3643, 5715, 3609, 2959, 1293, 3249, 5762, 1372, 1411, 1431, 1519, 1568, 1581, 1648, 1649, 1750, 1775, 1803, 1837, 1841, 1966, 1967, 1982, 2021, 2051, 2149, 2166, 2169, 2179, 2199, 2297, 2328, 2330, 2332, 2380, 2450, 2465, 2506, 2521, 2536, 2573, 2576, 2618, 2626, 2705, 2716, 2793, 2821, 2822, 2909, 3830, 3877, 3952, 3954, 4209, 4275, 4281, 4360, 4389, 4445, 4470, 4683, 4712, 4772, 4799, 4861, 4875, 4937, 4938, 5066, 5072, 5138, 5436, 5325, 2803, 3590, 2816, 2818, 2825, 2905, 2911, 2030, 3027, 1207, 1210, 5169, 5689, 5399, 3194, 5854, 5877, 3515, 4262, 3343, 2007, 2249, 1233, 5171, 2500, 2232, 2310, 2751, 3164, 5057, 275, 994, 4554, 4929, 1892, 2406, 2436, 2758, 2807, 3187, 3339, 3580, 4344, 4641, 5105, 5473, 5601, 5781, 6138, 1554, 1644, 2027, 5101, 2098, 3810, 4437, 4805, 4815, 4835, 4984, 4985, 4986, 1769, 912, 3648, 4260, 5467, 5521, 954, 5670, 32, 5400, 2458, 2549, 3096, 3864, 3942, 3945, 4481, 6103, 3220, 5696, 1477, 3397, 3429, 3534, 4393, 4597, 4662, 5502, 5938, 4453, 5646, 6083, 776, 3719, 5192, 5193, 5194, 5355, 5693, 5860, 167, 231, 5823, 483, 1171, 5700, 5831, 4217, 499, 2991, 4461, 4471, 4586, 1182, 4756, 382, 706, 5975, 5976, 5977, 5978, 5979, 2969, 5941, 43, 5168, 5172, 1544, 5128, 27, 5329, 6133, 3022, 3596, 5426, 2363, 3170, 3052, 3640, 3642, 5716, 5410, 648, 3425, 6003, 1146, 2850, 1350, 5404, 3737, 5655, 3315, 1909, 3662, 5164, 5147, 5489, 5257, 5240, 6128, 6134, 6147, 935, 2124, 3085, 3193, 2979, 3131, 6123, 5433, 2503, 5750, 1849, 1026, 1897, 2600, 2817, 2876, 2889, 2915, 2916, 3355, 3791, 3793, 3808, 3809, 3811, 3812, 3814, 3815, 3821, 3843, 3849, 3857, 3863, 3869, 3873, 3909, 3917, 3927, 3937, 3983, 3999, 4011, 4018, 4023, 4032, 4051, 4068, 4144, 4201, 4211, 4233, 4255, 4272, 4303, 4308, 4312, 4313, 4316, 4333, 4334, 4335, 4394, 4409, 4410, 4411, 4414, 4469, 4510, 4517, 4573, 4598, 4604, 4606, 4697, 4698, 4763, 4789, 4940, 5013, 5405, 3135, 3274, 3492, 5733, 3158, 5269, 3366, 3518, 4084, 4142, 4143, 5546, 3637, 5787, 2268, 5961, 726, 3678, 2861, 3236, 3354, 3586, 3671, 3850, 4130, 4366, 4387, 4388, 4512, 4515, 4537, 4538, 4541, 4542, 4557, 4560, 4626, 4627, 4757, 4779, 4780, 4943, 4975, 4976, 4982, 5112, 5113, 5640, 5528, 2869, 2513, 4374, 5940, 6122, 3044, 5401, 830, 3523, 5397, 2180, 1564, 5218, 3497, 3368, 1600, 2990, 3327, 3406, 5814, 2207, 3254, 4903, 1612, 3626, 3346, 5041, 2223, 3176, 2670, 5045, 2525, 5297, 2398, 2749, 2697, 3550, 5043, 1602, 3537, 5203, 5163, 3199, 6121, 3166, 5430, 3276, 5612, 5544, 1938, 2408, 5739, 3579, 5402, 0, 1014, 5278, 6021, 5989, 2452, 5310, 3256, 3773, 73, 3041, 1530, 2077, 3121, 3505, 1053, 4442, 2755, 2937, 3159, 3970, 4432, 4709, 82, 5857, 1822, 1992, 4199, 4353, 227, 1166, 3036, 2606, 3697, 1903, 5519, 2797, 60, 3508, 5455, 5768, 124, 2591, 3139, 4609, 858, 5488, 5514, 1498, 3860, 3943, 4022, 4160, 4267, 4268, 3752, 3141, 6114, 3091, 4351, 4352, 3439, 1442, 2052, 2279, 3432, 3399, 5742, 5490, 2022, 3077, 3083, 1706, 2341, 5219, 3694, 5421, 3415, 5432, 1654, 3112, 3144, 3387, 3418, 3758, 5363, 5364, 6146, 5855, 3654, 2725, 4824, 2110, 1844, 5538, 5232, 2340, 5708, 1610, 1899, 2025, 2389, 2476, 4521, 17, 2720, 5922, 5339, 1642, 3826, 5250, 1875, 2401, 1308, 5181, 5953, 3080, 1164, 3306, 3018, 133, 3717, 5802, 3561, 1504, 5174, 5175, 5515, 3670, 3464, 5991, 1924, 2594, 2439, 2432, 791, 418, 5207, 1725, 3242, 1432, 3023, 5682, 3190, 3446, 5068, 1594, 2126, 2335, 2429, 3162, 4247, 4714, 4897, 1577, 6142, 5623, 3817, 3835, 3984, 3985, 4071, 4422, 4443, 4444, 4447, 4596, 4684, 4685, 4869, 4927, 5039, 5129, 3273, 1507, 2372, 3311, 4009, 4115, 4150, 2545, 68, 1793, 20, 5873, 2343, 3233, 1345, 2633, 3260, 1434, 2776, 5639, 3295, 3543, 1292, 2694, 2205, 1974, 5406, 1277, 5443, 1847, 2824, 1039, 5312, 2574, 5335, 3755, 2781, 5683, 3587, 1558, 3482, 3571, 5956, 5767, 3127, 3839, 1227, 6056, 6057, 1888, 6130, 5653, 5740, 6052, 2892, 2968, 3332, 3414, 3865, 4064, 4140, 4182, 4186, 4187, 4307, 4317, 4324, 4679, 4996, 1325, 6041, 6042, 6043, 6044, 6047, 5198, 6119, 5225, 2970, 5368, 1218, 6050, 6051, 2061, 5452, 110, 5644, 1339, 3163, 5714, 5846, 107, 5638, 3189, 3280, 3289, 3296, 5617, 5279, 5604, 3784, 3859, 4093, 4239, 4558, 5002, 3511, 5196, 4702, 6156, 5876, 5239, 1566, 1933, 71, 3152, 56, 76, 5305, 3881, 4001, 4078, 4350, 4547, 4548, 4549, 4550, 4551, 4553, 4645, 4646, 4647, 4705, 4732, 4733, 4759, 4760, 4761, 5027, 5028, 5652, 5230, 4936, 5545, 2, 3766, 5393, 343, 4136, 4539, 1943, 3780, 1520, 2637, 3277, 5539, 3501, 5295, 1779, 902, 5301, 3619, 2874, 1360, 2457, 2654, 3529, 2424, 5464, 6029, 2752, 2819, 5577, 2923, 4884, 5303, 5486, 1715, 2680, 2290, 47, 1496, 1734, 1737, 2347, 2577, 2715, 4224, 3754, 6000, 6002, 1825, 3681, 5513, 1077, 5654, 2893, 4826, 2153, 3455, 1533, 1552, 1852, 1402, 1446, 1540, 1570, 1662, 1745, 1754, 1846, 1848, 1863, 1869, 1929, 1945, 2017, 2087, 2115, 2187, 2277, 2311, 2366, 2392, 2526, 2535, 2575, 2604, 2627, 2666, 2784, 2936, 3314, 3783, 3828, 4020, 4024, 4073, 4131, 4153, 4156, 4158, 4284, 4403, 4454, 4459, 4650, 4651, 4758, 4908, 4926, 5015, 5036, 5037, 5139, 4842, 62, 145, 5463, 5493, 2786, 121, 3329, 3569, 3602, 2069, 5191, 1996, 6108, 5484, 6102, 3020, 2374, 2691, 3053, 3286, 4543, 4907, 4710, 128, 5344, 5559, 1699, 3099, 3905, 3928, 3953, 3958, 4166, 4172, 4378, 4382, 4555, 4847, 4848, 5127, 534, 139, 1683, 1927, 5485, 361, 2985, 1694, 1713, 2839, 1390, 6111, 1808, 3157, 3655, 31, 2285, 6106, 5880, 3558, 1486, 3201, 5321, 4993, 4194, 1426, 1436, 1508, 2257, 3925, 3959, 4038, 5735, 3741, 5821, 2491, 2734, 2765, 4041, 4135, 4956, 2742, 2995, 3465, 93, 2625, 217, 5566, 1584, 1741, 1948, 1991, 3796, 3871, 3874, 4016, 4026, 4050, 4077, 4279, 4321, 4322, 4325, 4326, 4342, 4430, 4545, 4783, 4786, 4808, 4809, 4819, 4827, 4832, 4850, 4866, 4896, 4962, 5001, 5029, 5090, 4490, 3257, 81, 5859, 65, 5650, 471, 2686, 3759, 5574, 109, 3123, 3124, 6091, 3584, 140, 4775, 3718, 4849, 6109, 6110, 4769, 5119, 2238, 3445, 5770, 3449, 6148, 1930, 3459, 2497, 5204, 5242, 1532, 1883, 2049, 5188, 4594, 1971, 2605, 1790, 4885, 2226, 5686, 5531, 3674, 10, 3149, 21, 5992, 5993, 5353, 1382, 5047, 3073, 2113, 1380, 1640, 1653, 2085, 2788, 4226, 709, 129, 26, 3182, 1727, 3104, 1729, 37, 36, 5756, 3667, 3820, 4132, 4502, 4508, 4579, 5532, 2412, 5972, 6058, 1799, 5713, 5872, 1871, 1573, 5202, 3006, 1445, 3526, 79, 1795, 5317, 6093, 5460, 6150, 2320, 6092, 3290, 3330, 1429, 3134, 1310, 4844, 1012, 5569, 108, 3767, 6073, 3054, 3206, 4677, 1491, 114, 4111, 103, 1632, 5888, 4346, 1881, 3178, 5816, 2101, 2067, 112, 3778, 5226, 1517, 4468, 2080, 2569, 1148, 2331, 3727, 5281, 2651, 5480, 2178, 3723, 6143, 3753, 3761, 5359, 2484, 1801, 2487, 5687, 5557, 5996, 3223, 6080, 1833, 135, 1443, 3059, 1513, 3369, 2237, 6131, 2994, 5783, 1609, 1853, 5322, 4496, 5705, 2823, 2939, 11, 44, 5428, 5866, 5962, 100, 2510, 2677, 5839, 1470, 3116, 5856, 3789, 2259, 5631, 5960, 2872, 1998, 3173, 3218, 4552, 4607, 4707, 5692, 2530, 1563, 1693, 2782, 5637, 5523, 4742, 4959, 4966, 1531, 520, 57, 6087, 6129, 5504, 5858, 1474, 2035, 3360, 1785, 2522, 3601, 5679, 5963, 3384, 3400, 3651, 6090, 2721, 3008, 3876, 4088, 4572, 5077, 5079, 1551, 5641, 6126, 3359, 3409, 2532, 3353, 5812, 2111, 2785, 4188, 1151, 5610, 3570, 1922, 5717, 2160, 2468, 1843, 49, 2266, 29, 2405, 3394, 692, 1783, 1657, 2270, 2005, 4912, 3408, 3765, 5190, 1885, 1454, 1865, 6154, 5365, 3219, 1407, 1744, 2231, 3932, 3933, 3971, 3974, 3977, 4085, 4159, 4568, 3065, 3210, 5162, 1469, 5166, 3597, 4337, 2150, 4283, 2417, 2327, 2512, 4396, 4397, 4398, 5772, 2302, 5757, 3312, 66, 3625, 3560, 5827, 2659, 1575, 1740, 3142, 2717, 4455, 3009, 1985, 4817, 2252, 2735, 1481, 5354, 2955, 2787, 2209, 5392, 1760, 5458, 5311, 104, 3047, 5483, 1940, 5818, 3673, 2848, 6118, 5921, 3062, 3422, 3443, 1337, 2133, 2339, 5525, 5416, 5830, 5850, 5958, 48, 4215, 1859, 2260, 3824, 4052, 4076, 4210, 2075, 2377, 5573, 6039, 2671, 5564, 3217, 61, 97, 5720, 64, 3030, 3301, 1807, 3742, 3435, 5498, 4930, 5911, 1815, 1828, 2218, 2262, 2263, 2511, 2663, 3216, 150, 1777, 34, 3160, 3015, 5988, 2096, 2152, 3237, 3208, 1363, 1515, 3143, 1412, 3894, 3895, 3896, 4457, 4488, 5540, 3067, 3032, 3606, 5550, 2971, 3344, 5487, 6048, 6049, 6141, 2185, 5140, 6006, 3473, 1868, 2387, 3969, 5810, 5703, 3013, 1722, 2615, 2713, 4205, 4206, 4734, 4804, 4873, 1588, 1751, 2538, 2090, 1817, 3102, 3262, 3265, 3291, 3373, 5704, 5778, 4295, 5964, 2026, 5793, 4788, 4853, 5813, 3061, 2044, 3154, 3165, 4947, 1759, 5419, 3093, 3106, 3168, 3240, 3362, 5161, 5283, 699, 2981, 3617, 2863, 3357, 3530, 4191, 4338, 2885, 2037, 5444, 5445, 1856, 1502, 5950, 4197, 3167, 1542, 2910, 3883, 5475, 1440, 3564, 1546, 4198, 4676, 4582, 1384, 2046, 2105, 2107, 2221, 4225, 1893, 3150, 5327, 6115, 1708, 1905, 5159, 6132, 1755, 2507, 4994, 28, 78, 1723, 3618, 4519, 5046, 1370, 3633, 3676, 2415, 3607, 2718, 790, 2855, 504, 3436, 2684, 2350, 5248, 3155, 3782, 3801, 3847, 3991, 3994, 3997, 3998, 4072, 4108, 4127, 4128, 4129, 4154, 4678, 4965, 2812, 2835, 2840, 2753, 2189, 5980, 3541, 1664, 3303, 5848, 5904, 3132, 1980, 4251, 1485, 4372, 4373, 4375, 4587, 4868, 5091, 5145, 5208, 5362, 2188, 4535, 5468, 5481, 2925, 2477, 1782, 2551, 4253, 4404, 4823, 5494, 2404, 3664, 4441, 3416, 1626, 1550, 2761, 2010, 4420, 2912, 5453, 1622, 2621, 46, 5658, 1827, 3251, 123, 3434, 3644, 5345, 6076, 4426, 5862, 2312, 2894, 1787, 1880, 2070, 2071, 2291, 2395, 2542, 3993, 4185, 4501, 5944, 3427, 2766, 5734, 1438, 2690, 4998, 3486, 2555, 1536, 3532, 1355, 4256, 4583, 5023, 5691, 4015, 1419, 5347, 5241, 3488, 3855, 2131, 5769, 126, 4053, 3608, 2222, 83, 3740, 5825, 2827, 3918, 4097, 4126, 4133, 4904, 5662, 5524, 3911, 3912, 5017, 3653, 3922, 1459, 1704, 1538, 3545, 2214, 5797, 5565, 3137, 5501, 3231, 3868, 3916, 3138, 2370, 2794, 3531, 2862, 35, 2640, 1576, 4696, 4152, 1645, 3458, 5299, 4781, 4958, 5465, 5864, 2764, 3528, 457, 5084, 1831, 4222, 5571, 3086, 1615, 5997, 2603, 5541, 6059, 6060, 6061, 6062, 6063, 5309, 2040, 2140, 2619, 5558, 4610, 4062, 3795, 5510, 5669, 3557, 3068, 1562, 1430, 6145, 2770, 1989, 4216, 3787, 5357, 5070, 4777, 4977, 4981, 2354, 1928, 1696, 2681, 3181, 3568, 4134, 4207, 4208, 4331, 4513, 4701, 5845, 5619, 5702, 1296, 745, 5605, 5606, 5178, 1375, 1423, 5331, 1490, 3040, 1712, 1557, 1569, 2906, 2907, 2908, 3924, 4522, 4919, 4978, 5022, 2601, 2419, 3049, 1414, 3410, 5284, 5286, 6089, 3421, 3539, 6015, 6016, 6017, 5320, 5832, 6077, 2117, 5875, 5806, 5116, 4098, 5668, 4963, 4964, 3110, 3548, 3136, 2265, 2204, 3456, 5338, 5456, 5624, 5625, 7, 5201, 5732, 2135, 3063, 5949, 3585, 5398, 1680, 2333, 5229, 3661, 3666, 5313, 2459, 5236, 3046, 5948, 3393, 5987, 4002, 5844, 2280, 1455, 1764, 2508, 3177, 3195, 3822, 3846, 3914, 3915, 3919, 3920, 3923, 3939, 4163, 4174, 4227, 4237, 4806, 5115, 5306, 5423, 4695, 2913, 3973, 4300, 4860, 1747, 4807, 2472, 3841, 3010, 3243, 3281, 1898, 3153, 3103, 5983, 3107, 3682, 3129, 4699, 3377, 5200, 5332, 2504, 1921, 5093, 3259, 5099, 4656, 4593, 3191, 22, 2159, 4546, 4236, 2628, 3192, 4047, 4048, 4703, 2967, 3573, 5801, 2400, 6140, 1703, 1468, 2935, 4234, 4484, 4494, 4876, 4957, 5086, 1716, 1811, 1953, 2082, 2109, 2288, 2409, 2438, 2480, 2557, 2650, 2772, 2815, 3878, 3879, 3880, 3882, 3885, 3887, 3995, 4173, 4175, 4180, 4181, 4294, 4299, 4363, 4793, 4795, 4946, 4950, 4951, 5019, 5141, 5142, 5143, 5144, 5779, 5861, 2596, 4302, 3050, 39, 5350, 2515, 3021, 5931, 2186, 1395, 4413, 2692, 3147, 4184, 4872, 4992, 5014, 5055, 1925, 2034, 2456, 2736, 4148, 4605, 4319, 5109, 2877, 3903, 4008, 4482, 1418, 1439, 1506, 1510, 1528, 1634, 1673, 1972, 2020, 2055, 2093, 2524, 2838, 2933, 3636, 3867, 3904, 4027, 4164, 4270, 4368, 4518, 4523, 4526, 4527, 4528, 4529, 4601, 4602, 4603, 4700, 4704, 4718, 4719, 4720, 4722, 4723, 4724, 4828, 4890, 4892, 4893, 4925, 4941, 4942, 4999, 5100, 2081, 3060, 3247, 1733, 4909, 3198, 2274, 1876, 3786, 3818, 3921, 4010, 4039, 4074, 4101, 4107, 2879, 4785, 2739, 1688, 4391, 5210, 4845, 4857, 2563, 1902, 3204, 4065, 2224, 4060, 3246, 2394, 2759, 5838, 2774, 6101, 5570, 3980, 1579, 5688, 1671, 3962, 4532, 3519, 2674, 2703, 2698, 1952, 2023, 2298, 4632, 2489, 3105, 3899, 1731, 2076, 2346, 3861, 4089, 4652, 4657, 4658, 4659, 4663, 4665, 4667, 4668, 5018, 2287, 3426, 3203, 1766, 2682, 2726, 2593, 3285, 3635, 5536, 5568, 5342, 2053, 2747, 2629, 5709, 4315, 4534, 5031, 2613, 4090, 4139, 4141, 1920, 3345, 3388, 6097, 5819, 4117, 4271, 3253, 2422, 2865, 2866, 2867, 2868, 4192, 4204, 4219, 4390, 2983, 1401, 4386, 4433, 4438, 92, 3575, 5643, 2373, 2897, 2235, 3133, 3148, 5792, 3802, 3819, 3935, 3944, 3946, 3947, 3975, 3978, 4044, 4086, 4099, 4112, 4167, 4170, 4176, 4189, 4401, 4402, 4405, 4406, 4407, 4615, 4922, 4923, 5082, 5130, 5132, 5133, 5134, 5135, 5136, 5137, 3750, 1427, 4289, 4290, 1778, 2244, 2516, 2568, 2696, 2800, 1381, 1543, 1590, 1605, 1796, 1890, 1949, 3227, 3324, 3938, 3940, 3963, 3990, 4028, 4066, 4263, 4296, 4648, 4649, 4713, 4725, 4955, 3186, 1629, 3255, 1862, 4592, 4972, 4979, 3270, 4821, 4822, 1365, 4348, 4349, 2471, 4087, 3045, 5725, 2702, 1686, 2706, 1786, 1956, 1997, 2278, 3225, 2527, 1173, 3930, 5296, 5678, 5035, 3423, 14, 3378, 1774, 2064, 1405, 86, 1541, 2379, 3535, 1620, 1631, 1961, 1, 1618, 1917, 2032, 2123, 2132, 2281, 2517, 2622, 2655, 3844, 3555, 3833, 3908, 3910, 4213, 4624, 5033, 5146, 5746, 5795, 3407, 3420, 3629, 5837, 3328, 3785, 1582, 2177, 2407, 3090, 4171, 4230, 4231, 4623, 5741, 5506, 3298, 2679, 1802, 4431, 4486, 4625, 3475, 4932, 3263, 3272, 3035, 4812, 3072, 4254, 2361, 5675, 3834, 3884, 4503, 1855, 4856, 5282, 4980, 1614, 4810, 3171, 2987, 3028, 3183, 3567, 5336, 5672, 1656, 1663, 1672, 1975, 2799, 2921, 1305, 1695, 5951, 3304, 1621, 1674, 2065, 2707, 3893, 3961, 4581, 3949, 1611, 2375, 3064, 3114, 3293, 2095, 3831, 3950, 3996, 4745, 4803, 1635, 1169, 2841, 4365, 5253, 1451, 2537, 3853, 4035, 4157, 4691, 4692, 4693, 3391, 1357, 1522, 2466, 4525, 4680, 4882, 4891, 5032, 5764, 1163, 1914, 4770, 4487, 2631, 5986, 1702, 1691, 5749, 1913, 3451, 4358, 4562, 2246, 2351, 1738, 5729, 2612, 1976, 3269, 5947, 5954, 2854, 1806, 6018, 3461, 1762, 3533, 2662, 2849, 4385, 1408, 5572, 4889, 3430, 1639, 2197, 2763, 2998, 3337, 3380, 3450, 3489, 4202, 4768, 1523, 3305, 4584, 54, 3372, 1537, 2167, 2396, 5220, 2502, 3463, 2760, 2842, 4214, 4418, 4485, 4520, 4565, 4567, 4858, 4877, 4911, 4924, 4933, 4934, 4935, 1647, 1567, 4220, 4509, 1417, 1995, 2079, 2390, 2775, 1467, 2479, 2289, 3367, 3100, 5087, 2060, 2748, 3813, 4105, 4238, 4250, 1912, 5308, 3448, 3470, 2144, 2019, 5957, 72, 3856, 4478, 1918, 5497, 4005, 2728, 1452, 1836, 2608, 4103, 4576, 4577, 4578, 3647, 3502, 1947, 5807, 6098, 3169, 5216, 1904, 3447, 6088, 134, 5534, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 5048, 5049, 5050, 3870, 3979, 4012, 4034, 4036, 4067, 4104, 4619, 3109, 3699, 5094, 2708, 4458, 4899, 5083, 2565, 4258, 1585, 1810, 2054, 2501, 4682, 4764, 4854, 4855, 4887, 3556, 3334, 2047, 2084, 4328, 5108, 4531, 4791, 33, 3371, 2745, 4282, 3612, 3650, 2541, 4564, 5052, 4369, 2989, 3598, 5649, 2430, 2453, 3982, 4874, 4054, 1969, 1950, 2719, 3491, 1529, 40, 5622, 1466, 2239, 2264, 2355, 2475, 2641, 2645, 2783, 3356, 3576, 4343, 4356, 4357, 4620, 4622, 4843, 4851, 5038, 2584, 3278, 2740, 5449, 3457, 3151, 1398, 63, 3677, 5251, 5712, 3229, 1851, 2828, 3495, 1595, 1613, 1878, 1962, 2195, 2324, 2811, 4046, 4091, 4094, 4095, 4096, 4102, 2145, 2170, 2421, 1638, 2445, 5462, 3282, 1465, 3258, 2083, 1378, 2299, 2460, 4037, 5106, 5107, 2114, 1356, 2878, 3226, 3385, 5518, 1428, 1999, 2203, 3228, 3413, 3641, 3790, 3872, 1377, 5287, 2768, 2552, 3087, 3646, 3902, 3968, 4017, 5081, 2134, 3581, 3288, 3323, 5503, 5537, 1162, 1170, 3798, 3799, 3248, 1416, 3174, 5620, 6014, 2999, 3211, 3238, 3503, 3685, 1524, 4339, 4293, 5056, 5583, 6116, 2661, 3117, 5291, 53, 2171, 2240, 3837, 3252, 2125, 2492, 1472, 1901, 2172, 2192, 6124, 2014, 3559, 3403, 3659, 3140, 1721, 4421, 4694, 3419, 3788, 4045, 4070, 4901]\n"
     ]
    }
   ],
   "source": [
    "print(indices_in_order)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
