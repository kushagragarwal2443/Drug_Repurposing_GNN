{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912ad475-f8be-4229-8a99-c09d00d07dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# import torch_sparse\n",
    "# print(torch_sparse.__version__)\n",
    "\n",
    "import torch_geometric\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b92259b-90ae-4125-81bb-cc035da5b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "# import torch.sparse as tsp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv, HeteroConv, GraphConv\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import HeteroData\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file = '../data/final_data_dict.pkl'\n",
    "with open(file, 'rb') as f:   # the whole dataset\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    \n",
    "class HeteroGNN_GraphConv(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('disease', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('protein', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('drug', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('disease', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('protein', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "class HeteroGNN_SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('disease', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('protein', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('drug', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('disease', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('protein', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "def create_pyg_heterograph(data):\n",
    "    graph = HeteroData()\n",
    "\n",
    "    drug_feat = torch.tensor(data['d_feat'], dtype=torch.float32)\n",
    "    disease_feat = torch.tensor(data['dis_feat'], dtype=torch.float32)\n",
    "    protein_feat = torch.tensor(data['p_feat'], dtype=torch.float32)\n",
    "    if drug_feat.is_sparse:\n",
    "        drug_feat = drug_feat.to_dense()\n",
    "    if disease_feat.is_sparse:\n",
    "        disease_feat = disease_feat.to_dense()\n",
    "    if protein_feat.is_sparse:\n",
    "        protein_feat = protein_feat.to_dense()\n",
    "    graph['drug'].x = drug_feat\n",
    "    graph['disease'].x = disease_feat\n",
    "    graph['protein'].x = protein_feat\n",
    "    \n",
    "    drug_disease_edge_index = torch.stack([\n",
    "        torch.tensor(data['dd_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['dd_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    drug_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['dp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['dp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    disease_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['disp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['disp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    protein_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['pp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['pp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    graph['disease', 'interacts', 'drug'].edge_index = drug_disease_edge_index\n",
    "    graph['drug', 'interacts', 'protein'].edge_index = drug_protein_edge_index\n",
    "    graph['disease', 'interacts', 'protein'].edge_index = disease_protein_edge_index\n",
    "    graph['protein', 'interacts', 'protein'].edge_index = protein_protein_edge_index\n",
    "    \n",
    "    return graph\n",
    "    \n",
    "def generate_negative_pairs(num_diseases, num_drugs, positive_pairs, num_neg_samples=None):\n",
    "    positive_set = set((disease.item(), drug.item()) for disease, drug in zip(positive_pairs[0], positive_pairs[1]))\n",
    "    all_possible_pairs = [(disease, drug) for disease in range(num_diseases) for drug in range(num_drugs)]\n",
    "    negative_candidates = [(disease, drug) for disease, drug in all_possible_pairs if (disease, drug) not in positive_set]\n",
    "    if num_neg_samples is None:\n",
    "        num_neg_samples = len(positive_pairs[0])\n",
    "    neg_pairs = random.sample(negative_candidates, num_neg_samples)\n",
    "    neg_pairs = torch.tensor(neg_pairs, dtype=torch.long).t()\n",
    "    return neg_pairs\n",
    "\n",
    "def create_data_loaders(graph, num_parts=100, batch_size=32, shuffle=True):\n",
    "\n",
    "    num_disease_nodes = graph['disease'].x.size(0)\n",
    "    disease_1446_idx = 1446  # Ensure that COVID-19 to the test set\n",
    "\n",
    "    disease_indices = torch.arange(num_disease_nodes)\n",
    "    disease_indices = disease_indices[disease_indices != disease_1446_idx]  # Exclude disease 1446\n",
    "    \n",
    "    train_size = int(0.7 * num_disease_nodes)\n",
    "    val_size = int(0.15 * num_disease_nodes)\n",
    "    test_size = num_disease_nodes - train_size - val_size - 1  # Account for disease 1446\n",
    "    \n",
    "    train_subset, val_subset, test_subset = random_split(disease_indices, [train_size, val_size, test_size])\n",
    "\n",
    "    train_idx = torch.tensor(train_subset.indices)\n",
    "    val_idx = torch.tensor(val_subset.indices)\n",
    "    test_idx = torch.tensor(test_subset.indices)\n",
    "    test_idx = torch.cat([test_idx, torch.tensor([disease_1446_idx])])\n",
    "    \n",
    "    train_loader = NeighborLoader(\n",
    "        graph,\n",
    "        input_nodes=('disease', train_idx),\n",
    "        num_neighbors=num_parts,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    val_loader = NeighborLoader(\n",
    "        graph,\n",
    "        input_nodes=('disease', val_idx),\n",
    "        num_neighbors=num_parts,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Validation data is not shuffled\n",
    "    )\n",
    "    test_loader = NeighborLoader(\n",
    "        graph,\n",
    "        input_nodes=('disease', test_idx),\n",
    "        num_neighbors=num_parts,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Test data is not shuffled\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "    \n",
    "def train_hetero_gnn_with_loader(train_loader, model, optimizer, device, num_epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Iterate over mini-batches\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "            # Positive and negative edges sampling\n",
    "            pos_edges = batch['disease', 'interacts', 'drug'].edge_index\n",
    "\n",
    "            num_diseases = batch['disease'].x.size(0)\n",
    "            num_drugs = batch['drug'].x.size(0)\n",
    "            neg_edges = generate_negative_pairs(num_diseases, num_drugs, pos_edges, num_neg_samples=len(pos_edges[0]))\n",
    "            \n",
    "            pos_score = (out['drug'][pos_edges[1]] * out['disease'][pos_edges[0]]).sum(dim=1)\n",
    "            neg_score = (out['drug'][neg_edges[1]] * out['disease'][neg_edges[0]]).sum(dim=1)\n",
    "            loss = torch.mean(F.softplus(neg_score - pos_score))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n",
    "\n",
    "def evaluate_model_with_loader(test_loader, model, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "            pos_edges = batch['disease', 'interacts', 'drug'].edge_index\n",
    "\n",
    "            num_diseases = batch['disease'].x.size(0)\n",
    "            num_drugs = batch['drug'].x.size(0)\n",
    "            neg_edges = generate_negative_pairs(num_diseases, num_drugs, pos_edges, num_neg_samples=len(pos_edges[0]))\n",
    "\n",
    "            pos_score = (out['drug'][pos_edges[1]] * out['disease'][pos_edges[0]]).sum(dim=1).sigmoid()\n",
    "            neg_score = (out['drug'][neg_edges[1]] * out['disease'][neg_edges[0]]).sum(dim=1).sigmoid()\n",
    "\n",
    "            scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "            labels = torch.cat([torch.ones(pos_score.size(0)), torch.zeros(neg_score.size(0))]).cpu().numpy()\n",
    "\n",
    "            auc = roc_auc_score(labels, scores)\n",
    "            f1 = f1_score(labels, (scores > 0.5).astype(int))\n",
    "            precision = precision_score(labels, (scores > 0.5).astype(int))\n",
    "            recall = recall_score(labels, (scores > 0.5).astype(int))\n",
    "\n",
    "            print(f\"AUC: {auc}, F1: {f1}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "def get_top_hits_for_disease(model, disease_index, graph, top_k=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(graph.x_dict, graph.edge_index_dict)\n",
    "    disease_feature = out['disease'][disease_index]\n",
    "    drug_scores = torch.matmul(out['drug'], disease_feature)\n",
    "    top_drugs = torch.topk(drug_scores, k=top_k).indices\n",
    "    return top_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64ccb4b-ece8-4b1f-b2e6-0c658320b7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating GraphConv model:\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m train_hetero_gnn_with_loader(train_loader, model, optimizer, device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluate Train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m evaluate_model_with_loader(train_loader, model, device)\n",
      "Cell \u001b[0;32mIn[11], line 172\u001b[0m, in \u001b[0;36mtrain_hetero_gnn_with_loader\u001b[0;34m(train_loader, model, optimizer, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m    169\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Iterate over mini-batches\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    173\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    174\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/loader/node_loader.py:147\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m input_data: NodeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[0;32m--> 147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_sampler\u001b[38;5;241m.\u001b[39msample_from_nodes(input_data)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:322\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_from_nodes\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m     inputs: NodeSamplerInput,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 322\u001b[0m     out \u001b[38;5;241m=\u001b[39m node_sample(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample)\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[1;32m    324\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:542\u001b[0m, in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     seed \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnode\n\u001b[1;32m    540\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtime\n\u001b[0;32m--> 542\u001b[0m out \u001b[38;5;241m=\u001b[39m sample_fn(seed, seed_time)\n\u001b[1;32m    543\u001b[0m out\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m (inputs\u001b[38;5;241m.\u001b[39minput_id, inputs\u001b[38;5;241m.\u001b[39mtime)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:431\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     num_sampled_nodes \u001b[38;5;241m=\u001b[39m num_sampled_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-sparse\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_sampled_edges \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     num_sampled_edges \u001b[38;5;241m=\u001b[39m remap_keys(\n\u001b[1;32m    436\u001b[0m         num_sampled_edges,\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_edge_type,\n\u001b[1;32m    438\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "graph = create_pyg_heterograph(data)\n",
    "\n",
    "hidden_channels = 16\n",
    "out_channels = 4\n",
    "\n",
    "models = {\n",
    "    'GraphConv': HeteroGNN_GraphConv(hidden_channels, out_channels),\n",
    "    'GraphSAGE': HeteroGNN_SAGE(hidden_channels, out_channels)\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graph = graph.to(device)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(graph, num_parts=100, batch_size=32)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining and evaluating {model_name} model:\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    \n",
    "    train_hetero_gnn_with_loader(train_loader, model, optimizer, device)\n",
    "    print(\"\\nEvaluate Train\")\n",
    "    evaluate_model_with_loader(train_loader, model, device)\n",
    "    print(\"\\nEvaluate Val\")\n",
    "    evaluate_model_with_loader(val_loader, model, device)\n",
    "    print(\"\\nEvaluate Test\")\n",
    "    evaluate_model_with_loader(test_loader, model, device)\n",
    "    top_drugs = get_top_hits_for_disease(model, 1446, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a334e1-0709-484b-9391-b421e8759915",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models['GAT']\n",
    "best_model.load_state_dict(torch.load('best_model.pt'))\n",
    "# Use the best model for predictions or further analysis\n",
    "# For example, get top hits for multiple diseases\n",
    "disease_indices = [1446, 2000, 3000]  # example disease indices\n",
    "for disease_index in disease_indices:\n",
    "    top_drugs = get_top_hits_for_disease(best_model, disease_index, graph)\n",
    "    print(f\"Top drugs for disease index {disease_index}: {top_drugs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e9be3-edd9-45e1-b9fd-8340a0b600d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
