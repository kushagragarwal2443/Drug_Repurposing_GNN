{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912ad475-f8be-4229-8a99-c09d00d07dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.18\n",
      "2.4.0\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch_sparse\n",
    "print(torch_sparse.__version__)\n",
    "\n",
    "import torch_geometric\n",
    "print(torch_geometric.__version__)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b92259b-90ae-4125-81bb-cc035da5b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.sparse as tsp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader, NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv, HeteroConv, GraphConv\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import HeteroData\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file = '../data/final_data_dict.pkl'\n",
    "with open(file, 'rb') as f:   # the whole dataset\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    \n",
    "class HeteroGNN_GraphConv(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('disease', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "            ('protein', 'interacts', 'protein'): GraphConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('drug', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('disease', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('protein', 'interacts', 'protein'): GraphConv((hidden_channels, hidden_channels), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "class HeteroGNN_SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('drug', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('disease', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('protein', 'interacts', 'protein'): SAGEConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('disease', 'interacts', 'drug'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('drug', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('disease', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "            ('protein', 'interacts', 'protein'): SAGEConv((hidden_channels, hidden_channels), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "def create_pyg_heterograph(data):\n",
    "    graph = HeteroData()\n",
    "\n",
    "    drug_feat = torch.tensor(data['d_feat'], dtype=torch.float32)\n",
    "    disease_feat = torch.tensor(data['dis_feat'], dtype=torch.float32)\n",
    "    protein_feat = torch.tensor(data['p_feat'], dtype=torch.float32)\n",
    "    if drug_feat.is_sparse:\n",
    "        drug_feat = drug_feat.to_dense()\n",
    "    if disease_feat.is_sparse:\n",
    "        disease_feat = disease_feat.to_dense()\n",
    "    if protein_feat.is_sparse:\n",
    "        protein_feat = protein_feat.to_dense()\n",
    "    graph['drug'].x = drug_feat\n",
    "    graph['disease'].x = disease_feat\n",
    "    graph['protein'].x = protein_feat\n",
    "    \n",
    "    drug_disease_edge_index = torch.stack([\n",
    "        torch.tensor(data['dd_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['dd_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    drug_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['dp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['dp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    disease_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['disp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['disp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    protein_protein_edge_index = torch.stack([\n",
    "        torch.tensor(data['pp_adj'].row, dtype=torch.long),\n",
    "        torch.tensor(data['pp_adj'].col, dtype=torch.long)\n",
    "    ])\n",
    "    graph['disease', 'interacts', 'drug'].edge_index = drug_disease_edge_index\n",
    "    graph['drug', 'interacts', 'protein'].edge_index = drug_protein_edge_index\n",
    "    graph['disease', 'interacts', 'protein'].edge_index = disease_protein_edge_index\n",
    "    graph['protein', 'interacts', 'protein'].edge_index = protein_protein_edge_index\n",
    "    \n",
    "    return graph\n",
    "    \n",
    "def generate_negative_pairs(num_diseases, num_drugs, positive_pairs, num_neg_samples=None):\n",
    "    positive_set = set((disease.item(), drug.item()) for disease, drug in zip(positive_pairs[0], positive_pairs[1]))\n",
    "    all_possible_pairs = [(disease, drug) for disease in range(num_diseases) for drug in range(num_drugs)]\n",
    "    negative_candidates = [(disease, drug) for disease, drug in all_possible_pairs if (disease, drug) not in positive_set]\n",
    "    if num_neg_samples is None:\n",
    "        num_neg_samples = len(positive_pairs[0])\n",
    "    neg_pairs = random.sample(negative_candidates, num_neg_samples)\n",
    "    neg_pairs = torch.tensor(neg_pairs, dtype=torch.long).t()\n",
    "    return neg_pairs\n",
    "\n",
    "def create_data_loaders(graph, num_parts=100, batch_size=32, shuffle=True):\n",
    "\n",
    "    cluster_data = ClusterData(graph, num_parts=num_parts)\n",
    "    num_clusters = len(cluster_data)\n",
    "    train_size = int(0.7 * num_clusters)\n",
    "    val_size = int(0.15 * num_clusters)\n",
    "    test_size = num_clusters - train_size - val_size\n",
    "    train_idx, val_idx, test_idx = random_split(torch.arange(num_clusters), [train_size, val_size, test_size])\n",
    "    train_loader = ClusterLoader(cluster_data, batch_size=batch_size, shuffle=shuffle, cluster_idx=train_idx)\n",
    "    val_loader = ClusterLoader(cluster_data, batch_size=batch_size, shuffle=False, cluster_idx=val_idx)\n",
    "    test_loader = ClusterLoader(cluster_data, batch_size=batch_size, shuffle=False, cluster_idx=test_idx)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "    # # Get the number of 'disease' nodes\n",
    "    # num_disease_nodes = graph['disease'].x.size(0)\n",
    "    \n",
    "    # # 70%, 15%, 15% split\n",
    "    # train_size = int(0.7 * num_disease_nodes)\n",
    "    # val_size = int(0.15 * num_disease_nodes)\n",
    "    # test_size = num_disease_nodes - train_size - val_size\n",
    "\n",
    "    # # Split the indices for 'disease' nodes into train, validation, and test sets\n",
    "    # train_idx, val_idx, test_idx = random_split(torch.arange(num_disease_nodes), [train_size, val_size, test_size])\n",
    "\n",
    "    # train_loader = NeighborLoader(\n",
    "    #     graph,\n",
    "    #     input_nodes=('disease', train_idx),\n",
    "    #     num_neighbors=num_neighbors,\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=shuffle,\n",
    "    # )\n",
    "\n",
    "    # val_loader = NeighborLoader(\n",
    "    #     graph,\n",
    "    #     input_nodes=('disease', val_idx),\n",
    "    #     num_neighbors=num_neighbors,\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=False,  # Validation data is not shuffled\n",
    "    # )\n",
    "\n",
    "    # test_loader = NeighborLoader(\n",
    "    #     graph,\n",
    "    #     input_nodes=('disease', test_idx),\n",
    "    #     num_neighbors=num_neighbors,\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=False,  # Test data is not shuffled\n",
    "    # )\n",
    "\n",
    "    # return train_loader, val_loader, test_loader\n",
    "    \n",
    "def train_hetero_gnn_with_loader(train_loader, model, optimizer, device, num_epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Iterate over mini-batches\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "            # Positive and negative edges sampling\n",
    "            pos_edges = batch['disease', 'interacts', 'drug'].edge_index\n",
    "\n",
    "            num_diseases = batch['disease'].x.size(0)\n",
    "            num_drugs = batch['drug'].x.size(0)\n",
    "            neg_edges = generate_negative_pairs(num_diseases, num_drugs, pos_edges, num_neg_samples=len(pos_edges[0]))\n",
    "            \n",
    "            pos_score = (out['drug'][pos_edges[1]] * out['disease'][pos_edges[0]]).sum(dim=1)\n",
    "            neg_score = (out['drug'][neg_edges[1]] * out['disease'][neg_edges[0]]).sum(dim=1)\n",
    "            loss = torch.mean(F.softplus(neg_score - pos_score))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n",
    "\n",
    "        # Add validation logic here if needed\n",
    "        # For now, we'll skip it for brevity\n",
    "\n",
    "# Update evaluation function to use the NeighborLoader\n",
    "def evaluate_model_with_loader(test_loader, model, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "            pos_edges = batch['disease', 'interacts', 'drug'].edge_index\n",
    "\n",
    "            num_diseases = batch['disease'].x.size(0)\n",
    "            num_drugs = batch['drug'].x.size(0)\n",
    "            neg_edges = generate_negative_pairs(num_diseases, num_drugs, pos_edges, num_neg_samples=len(pos_edges[0]))\n",
    "\n",
    "            pos_score = (out['drug'][pos_edges[1]] * out['disease'][pos_edges[0]]).sum(dim=1).sigmoid()\n",
    "            neg_score = (out['drug'][neg_edges[1]] * out['disease'][neg_edges[0]]).sum(dim=1).sigmoid()\n",
    "\n",
    "            scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "            labels = torch.cat([torch.ones(pos_score.size(0)), torch.zeros(neg_score.size(0))]).cpu().numpy()\n",
    "\n",
    "            auc = roc_auc_score(labels, scores)\n",
    "            f1 = f1_score(labels, (scores > 0.5).astype(int))\n",
    "            precision = precision_score(labels, (scores > 0.5).astype(int))\n",
    "            recall = recall_score(labels, (scores > 0.5).astype(int))\n",
    "\n",
    "            print(f\"AUC: {auc}, F1: {f1}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "# Get top drug hits for a disease\n",
    "def get_top_hits_for_disease(model, disease_index, graph, top_k=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(graph.x_dict, graph.edge_index_dict)\n",
    "    disease_feature = out['disease'][disease_index]\n",
    "    drug_scores = torch.matmul(out['drug'], disease_feature)\n",
    "    top_drugs = torch.topk(drug_scores, k=top_k).indices\n",
    "    return top_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f64ccb4b-ece8-4b1f-b2e6-0c658320b7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HeteroData' has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m create_data_loaders(graph, num_parts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Train and evaluate each model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[22], line 122\u001b[0m, in \u001b[0;36mcreate_data_loaders\u001b[0;34m(graph, num_parts, batch_size, shuffle)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_data_loaders\u001b[39m(graph, num_parts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 122\u001b[0m     cluster_data \u001b[38;5;241m=\u001b[39m ClusterData(graph, num_parts\u001b[38;5;241m=\u001b[39mnum_parts)\n\u001b[1;32m    123\u001b[0m     num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cluster_data)\n\u001b[1;32m    124\u001b[0m     train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m num_clusters)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/loader/cluster.py:59\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, data, num_parts, recursive, save_dir, log, keep_inter_cluster_edges)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClusterData\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Clusters/partitions a graph data object into multiple subgraphs, as\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    motivated by the `\"Cluster-GCN: An Efficient Algorithm for Training Deep\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    and Large Graph Convolutional Networks\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m            partitions. (default: :obj:`\"csr\"`)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m---> 59\u001b[0m         data,\n\u001b[1;32m     60\u001b[0m         num_parts: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     61\u001b[0m         recursive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m         save_dir: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     63\u001b[0m         filename: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     64\u001b[0m         log: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m         keep_inter_cluster_edges: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m         sparse_format: Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m     ):\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m sparse_format \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/data/hetero_data.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    149\u001b[0m             out._edge_store_dict[key] = EdgeStorage(\n\u001b[1;32m    150\u001b[0m                 _parent=out, _key=key, **value)\n\u001b[1;32m    151\u001b[0m     return out\n\u001b[1;32m    153\u001b[0m def __getattr__(self, key: str) -> Any:\n\u001b[1;32m    154\u001b[0m     # `data.*_dict` => Link to node and edge stores.\n\u001b[1;32m    155\u001b[0m     # `data.*` => Link to the `_global_store`.\n\u001b[0;32m--> 156\u001b[0m     # Using `data.*_dict` is the same as using `collect()` for collecting\n\u001b[1;32m    157\u001b[0m     # nodes and edges features.\n\u001b[1;32m    158\u001b[0m     if hasattr(self._global_store, key):\n\u001b[1;32m    159\u001b[0m         return getattr(self._global_store, key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "graph = create_pyg_heterograph(data)\n",
    "\n",
    "hidden_channels = 16\n",
    "out_channels = 4\n",
    "\n",
    "# Initialize all models\n",
    "models = {\n",
    "    'GraphConv': HeteroGNN_GraphConv(hidden_channels, out_channels),\n",
    "    'GraphSAGE': HeteroGNN_SAGE(hidden_channels, out_channels)\n",
    "}\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graph = graph.to(device)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(graph, num_parts=100, batch_size=32)\n",
    "\n",
    "    # Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining and evaluating {model_name} model:\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training with the train loader\n",
    "    train_hetero_gnn_with_loader(train_loader, model, optimizer, device)\n",
    "\n",
    "    # Evaluation with the validation loader\n",
    "    evaluate_model_with_loader(val_loader, model, device)\n",
    "\n",
    "    # Final evaluation on the test set\n",
    "    evaluate_model_with_loader(test_loader, model, device)\n",
    "\n",
    "    # Get top hits for a specific disease (e.g., disease index 1446)\n",
    "    top_drugs = get_top_hits_for_disease(model, 1446, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a334e1-0709-484b-9391-b421e8759915",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models['GAT']\n",
    "best_model.load_state_dict(torch.load('best_model.pt'))\n",
    "# Use the best model for predictions or further analysis\n",
    "# For example, get top hits for multiple diseases\n",
    "disease_indices = [1446, 2000, 3000]  # example disease indices\n",
    "for disease_index in disease_indices:\n",
    "    top_drugs = get_top_hits_for_disease(best_model, disease_index, graph)\n",
    "    print(f\"Top drugs for disease index {disease_index}: {top_drugs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e9be3-edd9-45e1-b9fd-8340a0b600d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
