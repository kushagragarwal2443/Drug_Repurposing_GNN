{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7332791-1c39-484b-bae4-fc904e1ac436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagragarwal2443/anaconda3/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: \n",
      "attribute assignment is not defined on __torch__.torch_sparse.storage.SparseStorage:\n",
      "  File \"/Users/kushagragarwal2443/anaconda3/lib/python3.11/site-packages/torch_sparse/storage.py\", line 145\n",
      "    def empty(self):\n",
      "        self = SparseStorage.__new__(SparseStorage)\n",
      "        self._row = None\n",
      "        ~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self._rowptr = None\n",
      "        self._value = None\n",
      "\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv, HeteroConv\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78ec90f-9d33-4280-818c-0e462e709231",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/final_data_dict.pkl'\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "file = \"../data/processed_step2/map_drug.pkl\"\n",
    "with open(file, 'rb') as f:\n",
    "    drug_map = pickle.load(f)\n",
    "\n",
    "inverse_drug_map = {}\n",
    "for key in drug_map:\n",
    "    value = drug_map[key]\n",
    "    inverse_drug_map[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f17f75-c3e9-413e-b456-a52459d370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_index(adj_matrix):\n",
    "    edge_index = torch.tensor([adj_matrix.row, adj_matrix.col], dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "def generate_negative_samples(n_drug, n_prot, n_dis, pos_edge_index, num_samples):\n",
    "    disease_offset = n_drug + n_prot\n",
    "    pos_pairs = set(zip(pos_edge_index[0].cpu().numpy(), pos_edge_index[1].cpu().numpy()))\n",
    "    all_disease_drug_pairs = [(disease_offset + dis, drug) for dis in range(n_dis) for drug in range(n_drug)]\n",
    "    negative_pairs = [pair for pair in all_disease_drug_pairs if tuple(pair) not in pos_pairs]\n",
    "    sampled_negative_pairs = np.random.choice(len(negative_pairs), num_samples, replace=False)\n",
    "    negative_edge_index = torch.tensor([negative_pairs[i] for i in sampled_negative_pairs], dtype=torch.long).t()\n",
    "    return negative_edge_index\n",
    "\n",
    "class FeatureProjector(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FeatureProjector, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, drug_input_dim, protein_input_dim, disease_input_dim, hidden_channels, out_channels, feat_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.drug_projector = FeatureProjector(drug_input_dim, feat_dim)\n",
    "        self.protein_projector = FeatureProjector(protein_input_dim, feat_dim)\n",
    "        self.disease_projector = FeatureProjector(disease_input_dim, feat_dim)\n",
    "        self.conv1 = GCNConv(feat_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, drug_feat, protein_feat, disease_feat, edge_index):\n",
    "        drug_feat = self.drug_projector(drug_feat)\n",
    "        protein_feat = self.protein_projector(protein_feat)\n",
    "        disease_feat = self.disease_projector(disease_feat)\n",
    "        x = torch.cat([drug_feat, protein_feat, disease_feat], dim=0)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, drug_input_dim, protein_input_dim, disease_input_dim, n_heads, hidden_channels, out_channels, feat_dim):\n",
    "        super(GAT, self).__init__()\n",
    "        self.drug_projector = FeatureProjector(drug_input_dim, feat_dim)\n",
    "        self.protein_projector = FeatureProjector(protein_input_dim, feat_dim)\n",
    "        self.disease_projector = FeatureProjector(disease_input_dim, feat_dim)\n",
    "        self.conv1 = GATConv(feat_dim, hidden_channels, heads=n_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * n_heads, out_channels, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, drug_feat, protein_feat, disease_feat, edge_index):\n",
    "        drug_feat = self.drug_projector(drug_feat)\n",
    "        protein_feat = self.protein_projector(protein_feat)\n",
    "        disease_feat = self.disease_projector(disease_feat)\n",
    "        x = torch.cat([drug_feat, protein_feat, disease_feat], dim=0)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, drug_input_dim, protein_input_dim, disease_input_dim, hidden_channels, out_channels, feat_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.drug_projector = FeatureProjector(drug_input_dim, feat_dim)\n",
    "        self.protein_projector = FeatureProjector(protein_input_dim, feat_dim)\n",
    "        self.disease_projector = FeatureProjector(disease_input_dim, feat_dim)\n",
    "        self.conv1 = SAGEConv(feat_dim, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, drug_feat, protein_feat, disease_feat, edge_index):\n",
    "        drug_feat = self.drug_projector(drug_feat)\n",
    "        protein_feat = self.protein_projector(protein_feat)\n",
    "        disease_feat = self.disease_projector(disease_feat)\n",
    "        x = torch.cat([drug_feat, protein_feat, disease_feat], dim=0)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, drug_input_dim, protein_input_dim, disease_input_dim, hidden_channels, out_channels, feat_dim):\n",
    "        super(GIN, self).__init__()\n",
    "        self.drug_projector = FeatureProjector(drug_input_dim, feat_dim)\n",
    "        self.protein_projector = FeatureProjector(protein_input_dim, feat_dim)\n",
    "        self.disease_projector = FeatureProjector(disease_input_dim, feat_dim)\n",
    "        self.conv1 = GINConv(torch.nn.Sequential(torch.nn.Linear(feat_dim, hidden_channels), torch.nn.ReLU(), torch.nn.Linear(hidden_channels, hidden_channels)))\n",
    "        self.conv2 = GINConv(torch.nn.Sequential(torch.nn.Linear(hidden_channels, hidden_channels), torch.nn.ReLU(), torch.nn.Linear(hidden_channels, out_channels)))\n",
    "\n",
    "    def forward(self, drug_feat, protein_feat, disease_feat, edge_index):\n",
    "        drug_feat = self.drug_projector(drug_feat)\n",
    "        protein_feat = self.protein_projector(protein_feat)\n",
    "        disease_feat = self.disease_projector(disease_feat)\n",
    "        x = torch.cat([drug_feat, protein_feat, disease_feat], dim=0)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def train(model, optimizer, data, train_pos_edge_index, train_neg_edge_index, drug_feat, protein_feat, disease_feat):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model(drug_feat, protein_feat, disease_feat, data.edge_index)\n",
    "    pos_score = (z[train_pos_edge_index[0]] * z[train_pos_edge_index[1]]).sum(dim=1)\n",
    "    neg_score = (z[train_neg_edge_index[0]] * z[train_neg_edge_index[1]]).sum(dim=1)\n",
    "    all_scores = torch.cat(pos_score, neg_score)\n",
    "    all_truths = torch.cat(torch.ones_like(pos_score), torch.zeros_like(neg_score)e)\n",
    "    loss = F.binary_cross_entropy_with_logits(all_scores, all_truths)\n",
    "    # pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score))\n",
    "    # neg_loss = F.binary_cross_entropy_with_logits(neg_score, torch.zeros_like(neg_score))\n",
    "    # loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, test_pos_edge_index, test_neg_edge_index, drug_feat, protein_feat, disease_feat):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(drug_feat, protein_feat, disease_feat, data.edge_index)\n",
    "    \n",
    "    pos_score = (z[test_pos_edge_index[0]] * z[test_pos_edge_index[1]]).sum(dim=1).sigmoid()\n",
    "    neg_score = (z[test_neg_edge_index[0]] * z[test_neg_edge_index[1]]).sum(dim=1).sigmoid()\n",
    "    pos_labels = torch.ones(test_pos_edge_index.size(1))\n",
    "    neg_labels = torch.zeros(test_neg_edge_index.size(1))\n",
    "    \n",
    "    all_scores = torch.cat([pos_score, neg_score], dim=0)\n",
    "    all_labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "    \n",
    "    auc = roc_auc_score(all_labels.cpu(), all_scores.cpu())\n",
    "    f1 = f1_score(all_labels.cpu(), all_scores.cpu().round())\n",
    "    precision = precision_score(all_labels.cpu(), all_scores.cpu().round())\n",
    "    recall = recall_score(all_labels.cpu(), all_scores.cpu().round())\n",
    "    \n",
    "    return auc, f1, precision, recall\n",
    "\n",
    "def get_top_hits_for_disease(model, disease_index, data, drug_feat, protein_feat, disease_feat, n_drug, n_prot, top_k=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(drug_feat, protein_feat, disease_feat, data.edge_index)\n",
    "    disease_feature = z[n_drug + n_prot + disease_index]\n",
    "    drug_scores = torch.matmul(z[:n_drug], disease_feature)\n",
    "    top_drug_indices = drug_scores.topk(top_k).indices\n",
    "    top_drug_scores = drug_scores.topk(top_k).values\n",
    "    return (top_drug_indices, top_drug_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec91cd0-c93a-45a4-8bc8-878a6277bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = data['n_drug'] + data['n_prot'] + data['n_dis']\n",
    "\n",
    "n_drug = data['n_drug']\n",
    "n_prot = data['n_prot']\n",
    "n_dis = data['n_dis']\n",
    "\n",
    "drug_feat = torch.tensor(data['d_feat'], dtype=torch.float32)\n",
    "disease_feat = torch.tensor(data['dis_feat'], dtype=torch.float32)\n",
    "protein_feat = torch.tensor(data['p_feat'], dtype=torch.float32)\n",
    "if drug_feat.is_sparse:\n",
    "    drug_feat = drug_feat.to_dense()\n",
    "if disease_feat.is_sparse:\n",
    "    disease_feat = disease_feat.to_dense()\n",
    "if protein_feat.is_sparse:\n",
    "    protein_feat = protein_feat.to_dense()\n",
    "\n",
    "dp_edge_index = get_edge_index(data['dp_adj'])  # Drug-protein edges\n",
    "pp_edge_index = get_edge_index(data['pp_adj'])  # Protein-protein edges\n",
    "dd_edge_index = get_edge_index(data['dd_adj'])  # Disease-drug edges\n",
    "disp_edge_index = get_edge_index(data['disp_adj'])  # Disease-protein edges\n",
    "\n",
    "# Callibration for homo\n",
    "dp_edge_index[1] += n_drug  # Offset protein indices\n",
    "pp_edge_index += n_drug  # Offset both protein indices\n",
    "dd_edge_index[0] += n_drug + n_prot  # Offset disease indices\n",
    "disp_edge_index[0] += n_drug + n_prot  # Offset disease indices\n",
    "disp_edge_index[1] += n_drug  # Offset protein indices\n",
    "edge_index = torch.cat([dp_edge_index, pp_edge_index, dd_edge_index, disp_edge_index], dim=1)\n",
    "\n",
    "graph_data = Data(edge_index=edge_index)\n",
    "\n",
    "n_dd_edges = dd_edge_index.size(1)\n",
    "train_size = int(0.7 * n_dd_edges)\n",
    "val_size = int(0.15 * n_dd_edges)\n",
    "test_size = n_dd_edges - train_size - val_size\n",
    "\n",
    "train_edges, val_edges, test_edges = random_split(range(n_dd_edges), [train_size, val_size, test_size])\n",
    "train_pos_edge_index = dd_edge_index[:, train_edges.indices]\n",
    "val_pos_edge_index = dd_edge_index[:, val_edges.indices]\n",
    "test_pos_edge_index = dd_edge_index[:, test_edges.indices]\n",
    "\n",
    "neg_dd_edges_index = generate_negative_samples(n_drug, n_prot, n_dis, dd_edge_index, dd_edge_index.size(1))\n",
    "n_neg_dd_edges = neg_dd_edges_index.size(1)\n",
    "train_edges, val_edges, test_edges = random_split(range(n_neg_dd_edges), [train_size, val_size, test_size])\n",
    "train_neg_edge_index = neg_dd_edges_index[:, train_edges.indices]\n",
    "val_neg_edge_index = neg_dd_edges_index[:, val_edges.indices]\n",
    "test_neg_edge_index = neg_dd_edges_index[:, test_edges.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d4320c-1352-484d-9891-fdfa14fa57de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26109\n"
     ]
    }
   ],
   "source": [
    "print(n_drug + n_prot + 1446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e1612c-ac20-4341-9c75-0ae6c8ee57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26109, 253)\n",
      "(26109, 928)\n",
      "(26109, 3880)\n",
      "(26109, 1148)\n",
      "(26109, 3807)\n",
      "(26109, 5157)\n",
      "(26109, 514)\n",
      "(26109, 4783)\n",
      "(26109, 3027)\n",
      "(26109, 59)\n",
      "(26109, 2718)\n",
      "(26109, 5377)\n",
      "(26109, 1710)\n",
      "(26109, 2035)\n",
      "(26109, 2897)\n",
      "(26109, 3361)\n",
      "(26109, 2231)\n",
      "(26109, 1507)\n",
      "(26109, 1727)\n",
      "(26109, 418)\n",
      "(26109, 3354)\n",
      "(26109, 3492)\n",
      "(26109, 4541)\n",
      "(26109, 1321)\n",
      "(26109, 6054)\n",
      "(26109, 3273)\n",
      "(26109, 565)\n",
      "(26109, 4428)\n",
      "(26109, 5892)\n",
      "(26109, 3347)\n",
      "(26109, 5583)\n",
      "(26109, 5372)\n",
      "(26109, 1794)\n",
      "(26109, 3567)\n",
      "(26109, 2282)\n",
      "(26109, 2095)\n",
      "(26109, 2323)\n",
      "(26109, 103)\n",
      "(26109, 3527)\n",
      "(26109, 2803)\n",
      "(26109, 185)\n",
      "(26109, 5877)\n",
      "(26109, 624)\n",
      "(26109, 3584)\n",
      "(26109, 4259)\n",
      "(26109, 478)\n",
      "(26109, 6146)\n",
      "(26109, 3105)\n",
      "(26109, 584)\n",
      "(26109, 3406)\n",
      "(26109, 698)\n",
      "(26109, 1560)\n",
      "(26109, 3772)\n",
      "(26109, 3065)\n",
      "(26109, 2154)\n",
      "(26109, 3504)\n",
      "(26109, 2569)\n",
      "(26109, 2447)\n",
      "(26109, 4521)\n",
      "(26109, 1626)\n",
      "(26109, 5684)\n",
      "(26109, 3952)\n",
      "(26109, 3204)\n",
      "(26109, 4741)\n",
      "(26109, 5229)\n",
      "(26109, 724)\n",
      "(26109, 765)\n",
      "(26109, 4400)\n",
      "(26109, 4693)\n",
      "(26109, 1961)\n",
      "(26109, 2099)\n",
      "(26109, 5482)\n",
      "(26109, 1725)\n",
      "(26109, 2587)\n",
      "(26109, 416)\n",
      "(26109, 3238)\n",
      "(26109, 2807)\n",
      "(26109, 750)\n",
      "(26109, 3523)\n",
      "(26109, 3336)\n",
      "(26109, 116)\n",
      "(26109, 3263)\n",
      "(26109, 4987)\n",
      "(26109, 5662)\n",
      "(26109, 5817)\n",
      "(26109, 6069)\n",
      "(26109, 5362)\n",
      "(26109, 4451)\n",
      "(26109, 1418)\n",
      "(26109, 2093)\n",
      "(26109, 2207)\n",
      "(26109, 5541)\n",
      "(26109, 3484)\n",
      "(26109, 2199)\n",
      "(26109, 1077)\n",
      "(26109, 890)\n",
      "(26109, 4411)\n",
      "(26109, 5436)\n",
      "(26109, 6062)\n",
      "(26109, 1183)\n",
      "(26109, 801)\n",
      "(26109, 2802)\n",
      "(26109, 3103)\n",
      "(26109, 3989)\n",
      "(26109, 1631)\n",
      "(26109, 4705)\n",
      "(26109, 1664)\n",
      "(26109, 4112)\n",
      "(26109, 1404)\n",
      "(26109, 6137)\n",
      "(26109, 233)\n",
      "(26109, 4966)\n",
      "(26109, 949)\n",
      "(26109, 5121)\n",
      "(26109, 2153)\n",
      "(26109, 2031)\n",
      "(26109, 5666)\n",
      "(26109, 673)\n",
      "(26109, 2072)\n",
      "(26109, 2934)\n",
      "(26109, 340)\n",
      "(26109, 3349)\n",
      "(26109, 4585)\n",
      "(26109, 3487)\n",
      "(26109, 7)\n",
      "(26109, 3569)\n",
      "(26109, 788)\n",
      "(26109, 4171)\n",
      "(26109, 1390)\n",
      "(26109, 4724)\n",
      "(26109, 1130)\n",
      "(26109, 4204)\n",
      "(26109, 5367)\n",
      "(26109, 4497)\n",
      "(26109, 4123)\n",
      "(26109, 4050)\n",
      "(26109, 5026)\n",
      "(26109, 6067)\n"
     ]
    }
   ],
   "source": [
    "for i in set(zip(neg_dd_edges_index[0].cpu().numpy(), neg_dd_edges_index[1].cpu().numpy())):\n",
    "    if(i[0]==26109):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1552abd-ac52-42e6-bf15-7c08d9b1a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25123, 25840, 25861,  ..., 25968, 25066, 25578],\n",
      "        [  310,  1339,  3749,  ...,  5540,  5968,  6026]])\n"
     ]
    }
   ],
   "source": [
    "print(test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937a1928-5417-4df7-b522-de1e60611802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24798, 25496, 25206,  ..., 25016, 24759, 25157],\n",
      "        [  611,   777,   939,  ...,   370,   148,   272]])\n"
     ]
    }
   ],
   "source": [
    "print(test_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f9305bf-a950-4ea1-ac7f-1b9fa766a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!Starting Training for GCN\n",
      "\n",
      "Epoch 0, Loss: 1.3780534267425537\n",
      "Epoch 5, Loss: 0.9292418360710144\n",
      "Epoch 10, Loss: 0.840595543384552\n",
      "Epoch 15, Loss: 0.810621976852417\n",
      "Epoch 20, Loss: 0.7027738690376282\n",
      "Epoch 25, Loss: 0.4633846879005432\n",
      "Epoch 30, Loss: 0.30436503887176514\n",
      "Epoch 35, Loss: 0.2554895877838135\n",
      "Epoch 40, Loss: 0.24405644834041595\n",
      "Epoch 45, Loss: 0.22581179440021515\n",
      "Epoch 49, Loss: 0.21641214191913605\n",
      "\n",
      "Train Metrics:\tAUC: 0.9924, F1: 0.9601, Precision: 0.9379, Recall: 0.9835\n",
      "Val Metrics:\tAUC: 0.9902, F1: 0.9564, Precision: 0.9329, Recall: 0.9812\n",
      "\n",
      "Top drugs list for index 1446\n",
      "[280, 282, 74, 707, 887, 682, 355, 1073, 497, 465]\n",
      "[9.351, 8.324, 6.983, 6.896, 6.166, 5.695, 5.023, 4.378, 4.145, 4.064]\n",
      "['DB00313', 'DB00316', 'DB00091', 'DB00783', 'DB00977', 'DB00755', 'DB00396', 'DB01174', 'DB00550', 'DB00515']\n",
      "\n",
      "\n",
      "!!!!!!!!!!!Starting Training for GAT\n",
      "\n",
      "Epoch 0, Loss: 1.385980248451233\n",
      "Epoch 5, Loss: 0.6170543432235718\n",
      "Epoch 10, Loss: 0.49736154079437256\n",
      "Epoch 15, Loss: 0.46181535720825195\n",
      "Epoch 20, Loss: 0.40683692693710327\n",
      "Epoch 25, Loss: 0.38508230447769165\n",
      "Epoch 30, Loss: 0.3640040457248688\n",
      "Epoch 35, Loss: 0.3548537790775299\n",
      "Epoch 40, Loss: 0.33602651953697205\n",
      "Epoch 45, Loss: 0.35594385862350464\n",
      "Epoch 49, Loss: 0.3497222363948822\n",
      "\n",
      "Train Metrics:\tAUC: 0.9863, F1: 0.9234, Precision: 0.8664, Recall: 0.9885\n",
      "Val Metrics:\tAUC: 0.9824, F1: 0.9204, Precision: 0.8624, Recall: 0.9867\n",
      "\n",
      "Top drugs list for index 1446\n",
      "[237, 1678, 850, 1386, 2701, 1559, 1023, 1479, 555, 255]\n",
      "[0.747, 0.728, 0.722, 0.72, 0.718, 0.716, 0.716, 0.715, 0.713, 0.712]\n",
      "['DB00266', 'DB02285', 'DB00936', 'DB01698', 'DB04365', 'DB02052', 'DB01119', 'DB01880', 'DB00614', 'DB00286']\n",
      "\n",
      "\n",
      "!!!!!!!!!!!Starting Training for SAGE\n",
      "\n",
      "Epoch 0, Loss: 1.3934926986694336\n",
      "Epoch 5, Loss: 1.2442108392715454\n",
      "Epoch 10, Loss: 0.9120148420333862\n",
      "Epoch 15, Loss: 0.7558008432388306\n",
      "Epoch 20, Loss: 0.4203284978866577\n",
      "Epoch 25, Loss: 0.2942443788051605\n",
      "Epoch 30, Loss: 0.2648782432079315\n",
      "Epoch 35, Loss: 0.2093987762928009\n",
      "Epoch 40, Loss: 0.1981016993522644\n",
      "Epoch 45, Loss: 0.19224655628204346\n",
      "Epoch 49, Loss: 0.18721604347229004\n",
      "\n",
      "Train Metrics:\tAUC: 0.9933, F1: 0.9652, Precision: 0.9564, Recall: 0.9741\n",
      "Val Metrics:\tAUC: 0.9906, F1: 0.9581, Precision: 0.9489, Recall: 0.9673\n",
      "\n",
      "Top drugs list for index 1446\n",
      "[282, 707, 280, 74, 682, 887, 1073, 113, 451, 355]\n",
      "[2.397, 2.278, 2.235, 2.027, 1.9, 1.854, 1.722, 1.603, 1.492, 1.418]\n",
      "['DB00316', 'DB00783', 'DB00313', 'DB00091', 'DB00755', 'DB00977', 'DB01174', 'DB00134', 'DB00499', 'DB00396']\n",
      "\n",
      "\n",
      "!!!!!!!!!!!Starting Training for GIN\n",
      "\n",
      "Epoch 0, Loss: 1.0967907905578613\n",
      "Epoch 5, Loss: 1.0663694143295288\n",
      "Epoch 10, Loss: 1.0152480602264404\n",
      "Epoch 15, Loss: 1.011251449584961\n",
      "Epoch 20, Loss: 1.0031825304031372\n",
      "Epoch 25, Loss: 0.9976449608802795\n",
      "Epoch 30, Loss: 0.9911453127861023\n",
      "Epoch 35, Loss: 0.9869236946105957\n",
      "Epoch 40, Loss: 0.9762229323387146\n",
      "Epoch 45, Loss: 0.9173375368118286\n",
      "Epoch 49, Loss: 0.9445230960845947\n",
      "\n",
      "Train Metrics:\tAUC: 0.9609, F1: 0.6758, Precision: 0.5195, Recall: 0.9668\n",
      "Val Metrics:\tAUC: 0.9587, F1: 0.6758, Precision: 0.5197, Recall: 0.9657\n",
      "\n",
      "Top drugs list for index 1446\n",
      "[1470, 2959, 2012, 6040, 5310, 124, 2412, 4854, 3081, 1926]\n",
      "[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n",
      "['DB01863', 'DB04838', 'DB02963', 'DB14481', 'DB09070', 'DB00145', 'DB03753', 'DB08291', 'DB05024', 'DB02776']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_dim = 10  # The desired dimension after projection\n",
    "hidden_channels = 64\n",
    "out_channels = 16\n",
    "epochs = 50\n",
    "topk = 10\n",
    "n_heads = 4\n",
    "\n",
    "models = [GCN(drug_feat.shape[1], protein_feat.shape[1], disease_feat.shape[1], hidden_channels, out_channels, feat_dim),\n",
    "          GAT(drug_feat.shape[1], protein_feat.shape[1], disease_feat.shape[1], n_heads, hidden_channels, out_channels, feat_dim),\n",
    "          GraphSAGE(drug_feat.shape[1], protein_feat.shape[1], disease_feat.shape[1], hidden_channels, out_channels, feat_dim),\n",
    "          GIN(drug_feat.shape[1], protein_feat.shape[1], disease_feat.shape[1], hidden_channels, out_channels, feat_dim)]\n",
    "model_names = [\"GCN\", \"GAT\", \"SAGE\", \"GIN\"]\n",
    "\n",
    "top_drugs_dict = dict()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    name = model_names[i]\n",
    "    print(\"!!!!!!!!!!!Starting Training for\", name)\n",
    "    print()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        loss = train(model, optimizer, graph_data, train_pos_edge_index, train_neg_edge_index, drug_feat, protein_feat, disease_feat)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    print()\n",
    "    auc, f1, precision, recall = test(model, graph_data, train_pos_edge_index, train_neg_edge_index, drug_feat, protein_feat, disease_feat)\n",
    "    print(f\"Train Metrics:\\tAUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    auc, f1, precision, recall = test(model, graph_data, val_pos_edge_index, val_neg_edge_index, drug_feat, protein_feat, disease_feat)\n",
    "    print(f\"Val Metrics:\\tAUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "    print(\"\\nTop drugs list for index 1446\")\n",
    "    top_drugs, top_drugs_scores = get_top_hits_for_disease(model, 1446, graph_data, drug_feat, protein_feat, disease_feat, n_drug, n_prot, top_k=topk)\n",
    "    top_drugs = top_drugs.tolist()\n",
    "    top_drugs_scores = top_drugs_scores.tolist()\n",
    "    top_drugs_scores = [round(num, 3) for num in top_drugs_scores]\n",
    "    print(top_drugs)\n",
    "    print(top_drugs_scores)\n",
    "    top_drug_names = []\n",
    "    for drug in top_drugs:\n",
    "        top_drug_names.append(inverse_drug_map[drug])\n",
    "    print(top_drug_names)\n",
    "    top_drugs_dict[name] = top_drug_names\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a410f03-56f4-426d-86e3-20f81d34973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DB00313': 2, 'DB00316': 2, 'DB00091': 2, 'DB00783': 2, 'DB00977': 2, 'DB00755': 2, 'DB00396': 2, 'DB01174': 2, 'DB00550': 1, 'DB00515': 1, 'DB00266': 1, 'DB02285': 1, 'DB00936': 1, 'DB01698': 1, 'DB04365': 1, 'DB02052': 1, 'DB01119': 1, 'DB01880': 1, 'DB00614': 1, 'DB00286': 1, 'DB00134': 1, 'DB00499': 1, 'DB01863': 1, 'DB04838': 1, 'DB02963': 1, 'DB14481': 1, 'DB09070': 1, 'DB00145': 1, 'DB03753': 1, 'DB08291': 1, 'DB05024': 1, 'DB02776': 1}\n"
     ]
    }
   ],
   "source": [
    "drug_counts = {}\n",
    "for name in top_drugs_dict:\n",
    "    drug_list = top_drugs_dict[name]\n",
    "    for drug in drug_list:\n",
    "        if(drug not in drug_counts):\n",
    "            drug_counts[drug] = 0\n",
    "        drug_counts[drug]+=1\n",
    "\n",
    "sorted_dict = dict(sorted(drug_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f128eed2-0336-45b9-b2f5-fd8fe8dd94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Think about how data splitting is happening is it fair to allot negative edges randomly? Maybe not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
